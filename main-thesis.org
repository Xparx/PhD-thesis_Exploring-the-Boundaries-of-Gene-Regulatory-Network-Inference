# Time-stamp: <2015-11-09 11:12:49 andreas>
#+OPTIONS: title:t toc:nil todo:t |:t email:nil H:4
#+BIND: org-latex-title-command "\\selectlanguage{english}\n\\frontmatterSU\n\\halftitlepage\n\\maketitle"
#+TITLE: Exploring the Boundaries of Gene Regulatory Network Inference
#+DATE: \today
#+AUTHOR: Andreas Tjärnberg
#+EMAIL: andreas.tjarnberg@scilifelab.se
#+KEYWORDS:
#+LANGUAGE: en_GB
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 25.0.50.1 (Org mode 8.3)
#+LATEX_CMD: pdfbibtex
#+LATEX_CLASS: thesis-book-SU
#+LATEX_CLASS_OPTIONS: [twoside,11pt]
#+DESCRIPTION:
#+LATEX_HEADER: \subtitle{}
#+LATEX_HEADER_EXTRA: \hbadness=10000
#+LATEX_HEADER_EXTRA: \hfuzz=50pt
#+LATEX_HEADER_EXTRA: \input{glossaries-thesis}
#+LATEX_HEADER: \newcommand{\gs}{GeneSPIDER\xspace}

* Empty page                                                        :notitle:
#+begin_src latex :exports results :results latex
%: ----------------------- Cover page back side ------------------------
\newpage
\thispagestyle{empty}
#+end_src

* Document info                                                     :notitle:
#+begin_src latex :exports results :results latex
\clearpage

\phantom{.}

\vspace{\stretch{1}}

{\fontfamily{verdana}\selectfont
{\scriptsize
\noindent
\copyright Andreas Tjärnberg, Stockholms universitet 2015 % Name of author, location year

\vspace{5mm}
\noindent
ISBN 978-91-7649-299-4 % Provided by the library

\vspace{5mm}
\noindent
Print: Holmbergs, Malmö 2015 % name of printing company

\noindent
Distributor: Department of Biochemistry and Biophysics % name of department
}
}
\cleardoublepage
#+end_src

* Abstract                                                          :notitle:
#+begin_abstracts
To understand how the components of a complex system like a living cell interact and regulate each other, we need to collect data about how the components respond to system perturbations.
Such data can then be used to solve the inverse problem of inferring a network that describes how the pieces influence each other.
The work in this thesis concerns modelling of the regulatory system of a cell, often represented as a network. Common tools and concepts in systems biology are used.

The first investigation focuses on network sparsity and algorithmic
biases introduced by penalised network inference procedures.
Many contemporary network inference methods rely on a sparsity parameter,
such as the $L_1$ penalty term used in the \lasso.
However, a poor choice of the sparsity parameter can give highly incorrect network estimates.
In order to avoid such poor choices,
we devised a method to optimise the sparsity parameter, which
maximises the accuracy of the inferred network.
We showed that it is effective on \insilico data sets with a reasonable level of
informativeness and demonstrated that accurate prediction of network
sparsity is key to elucidate the correct network parameters.

The second investigation focuses on how knowledge from association networks can be used in regulatory network inference procedures.
The quality of expression data is typically inadequate for reliable [[gls:grn]] inference.
Therefore, we constructed an algorithm to incorporate prior knowledge and demonstrated that it increases the accuracy of network inference when the quality of the data is low.

The third investigation aimed to understand the influence of system and data properties on network inference accuracy.
$L_1$ regularisation methods commonly produce poor network estimates when the data is ill-conditioned,
even when the signal to noise ratio is so high that all links in the network can be proven to exist at the common significance level of 0.01.
In this study we elucidated general principles about the conditions for which we expect degraded accuracy.
Moreover, it allowed us to estimate the expected accuracy from observable properties of simulated data, that can be used to predict the performance of inference algorithms on biological data.

Finally, we built a software package \gs for solving problems encountered during previous investigations.
The software package supports highly controllable network and data generation, as well as data analysis and exploration in the context of network inference.
#+end_abstracts
\cleardoublepage
* Dedication                                                        :notitle:

#+begin_dedication
#+BEGIN_LaTeX
{\Large {\calligra To my grandmother Mildred}}
#+END_LaTeX
#+end_dedication

* List of Papers

#+begin_src latex :exports results :results latex
\vspace{-5pt} % Increase to have a larger space.

The following papers, referred to in the text by their Roman numerals, are included in this thesis.

\vspace{0pt} % Increase to have a larger space before the list is started.


\begin{enumerate}[P{A}PER I: ]
%\begin{enumerate}[I]

\setlength{\itemsep}{3.3mm} % Set the vertical distance between the items

% Suggested order
% Author 1 surname, Author 1 first name initial., Author 2 surname, Author 2 first name
% initial. etc. (Year of publication) Paper main title.
% Paper subtitle. Name of journal in italics, volume(number):page rage
% Example

\item\textbf{Optimal sparsity criteria for network inference.}\\
Tjärnberg A., Nordling T., Studham M., and Sonnhammer EL.
 \emph{Journal of Computational Biology}, \textbf{20(5)}, 398-4089 (2013).\\
DOI: \href{http://dx.doi.org/10.1089/cmb.2012.0268}{10.1089/cmb.2012.0268}

\item\textbf{Functional association networks as priors for gene regulatory network inference.}\\
Studham M., Tjärnberg A., Nordling T., Nelander S., and Sonnhammer EL. \emph{Bioinformatics}, \textbf{30(12)}, i130–i138 (2014).\\
DOI: \href{http://dx.doi.org/10.1093/bioinformatics/btu285}{10.1093/bioinformatics/btu285}

\item\textbf{Avoiding pitfalls in l1-regularised inference of gene networks.}\\
Tjärnberg A., Nordling T., Studham M., Nelander S., and Sonnhammer EL. \emph{Mol. BioSyst.}, \textbf{1(11)}, 287-296 (2015).\\
DOI: \href{http://dx.doi.org/10.1039/C4MB00419A}{10.1039/C4MB00419A}

\item\textbf{GeneSPIDER - Generation and Simulation Package for Informative Data ExploRation.}\\
Tjärnberg A., Nordling T., Morgan D., Studham M., and Sonnhammer EL.
\emph{manuscript.}, \textbf{}  (2015).\\

\end{enumerate}

\noindent
\rule{\linewidth}{0.5mm}

\vspace{2mm}

\noindent
Reprints were made with permission from the publishers.
#+end_src

* Table of content                                                  :notitle:
#+begin_src latex :exports results :results latex
%: ----------------------- Table of contents ------------------------

\setcounter{secnumdepth}{2} % organisational level that receives a numbers
\setcounter{tocdepth}{2}    % print table of contents for level 2
\tableofcontents            % print the table of contents
% levels are: 0 - chapter, 1 - section, 2 - subsection, 3 - subsubsection
#+end_src

* Abbreviations                                                     :notitle:
#+begin_src latex :exports results :results latex
% To create the glossary run the command
% $ makeglossaries main-thesis

%\nomrefpage % to include page numbers after abbrevations

% In the text type "\g" to refer to glossary

% \markboth{\MakeUppercase{\nomname}}{\MakeUppercase{\nomname}}

\begin{footnotesize} % scriptsize(7) < footnotesize(8) < small (9) < normal (10)
\printacronyms[title=Abbreviations,nonumberlist]
% \printglossary[type=\acronymtype,title=Abbreviations]
\label{nom} % target name for links to glossary
\end{footnotesize}
#+end_src

* Figures and tables                                                :notitle:
#+begin_src latex :exports results :results latex
% \listoffigures	% print list of figures
% \listoftables     % print list of tables
#+end_src

* Mainmatter                                                        :notitle:
#+begin_src latex :exports results :results latex
\mainmatterSU
#+end_src

* Introduction

# General what is systems
Biological systems are diverse and complex and not easily described by simple rules.
Whether it is the patterns of whole populations and societies, the interactions of individual organisms or the cellular, internal, and external machinery,
understanding biological systems is motivated by the need to predict, modify or enhance the behaviour or functions of these systems.
Gaining a mechanistic understanding of the system can help prevent outbreak of systemic failure (disease), as well as present the optimal course of action to restore base level functioning.
Thus, if cancer for example, is viewed as an unwanted state, or a breakdown of cellular function we would like to intervene and return the system to its natural state.
This could be done either by forcing the system to return to its original state or by selectively terminating the faulty cells without damaging healthy cells.
Understanding how the parts of the system interact helps to selectively target and steer the system as a whole to a desired state.

# Why do we need to look at things as systems of interactions
Components of these systems are capable of changing over time, responding to internal and external inputs in non-random ways, as well as transferring information among themselves.
A key observation of these systems is that their behaviour cannot be trivially understood or predicted by knowing any single component's properties.
However, emergent behaviours can be viewed as a result of placing several components in a specific context.
A component can be a anything from a gene or cell, to a population of cells or entire organisms.
A human cell, for example, cannot easily be grown in isolation without modifying its internal machinery to some state dissimilar from that which it exhibited \emph{in vivo}.
That is, the composition of the system is not complete without incorporating the interactions the components exert among themselves and the resultant behaviour that arises [[citep:Barabasi2004]].
It should be noted that a wide range of systems can be investigated using similar, contextually relevant concepts, and that knowledge can be derived indirectly from other areas of research, evidenced by comparisons between the structuring of different system interactions that display both common and disparate traits [[citep:Milo2002]].

# Focus on the cell
This thesis and the work herein aims to understand the intracellular machinery, specifically what we will call the \acrfull{grn}.

# Motivation for this work
The intracellular system cannot be accurately described isolated from its environment, and if it were, we could not assume that the behaviour would reflect that in its natural environment.
This observation makes studying these systems non-trivial.
Specific changes to the system are not easily induced, isolated or even measured.

Classically, if we want to study some phenomena of nature, we isolate it to the best of our ability and selectively change variables to build a picture of how the phenomena can best be described.
For the reasons mentioned above, compounded by the cheer number of components of the system, with around \mbox{20\,000} protein coding genes giving around \mbox{400\,000\,000} possible interactors within a single cell,
it is nearly impossible to isolate a biological system to such a degree yet on a large scale as to be confident that there are no disruptive unknown variables in play.
All studies considering more than a few components need to account for this effect and incorporate noise into their conclusions.

One aim of systems biology is to understand the structure and behaviour of biological systems on a specific hierarchical level, where the cell is but one example.
A thorough understanding of the boundaries and performance of the tools used and the properties of the experiments carried out is of prime importance.
The focus of the work done in this thesis is the study of properties of algorithms and data for constructing reliable models for representing biological systems.
To contribute to the possibility of inferring, from data, [[glspl:grn]] with high confidence, that accurately reflects the underlying biology, in order to
allow conclusions and knowledge to be derived from these models.

* Background

** Biological systems
:PROPERTIES:
:CUSTOM_ID: sec:bio_sys
:END:
Biological systems cover a wide range of different phenomena.
In this section I will go through the specific biological system referred to in this thesis, gene regulation in the cell.
This will, in part, motivate the need of the mathematical and computational modelling used in this research area.
The vast complexity of the cell is such that to account for all components and environmental factors that interact and regulate response in the cell is an intractable problem.
A core phenomenon of the cellular function is expression, \ie the regulation of when and how much of any given biomolecules are expressed.

*** Gene regulation and gene regulatory networks

#+CAPTION[Central dogma of molecular biology]: The central dogma of molecular biology [[citep:Brown2002]]. The flow of expression is shown left to right. Figure inspired by [[citet:Gardner2005]]
#+label: fig:central-dogma
[[file:img/central_dogma.pdf]]

Regulation in biological systems means the process of how an entity (biomolecule) controls the behaviour of another entity (biomolecule).
In the cell this can be the process of a protein binding to DNA to regulate how much of a specific gene becomes transcribed, where the protein is referred to as a [[gls:tf]].
When the [[gls:tf]]  binds to the gene-specific binding site, the interaction activates expression of the gene. If the [[gls:tf]] lowers or turns off the expression of a gene, the interaction is suppressing the gene.
The [[gls:tf]] /regulates/ the gene and this then counts as a regulation.
Figure [[ref:fig:central-dogma]] shows the flow of expression, where gene expression is a multistep process [[citep:Brown2002]].
First the gene is transcribed, converting a double stranded DNA nucleotide base sequence into a single stranded RNA molecule one or more times.
Second, the RNA molecule's nucleotide sequence is translated to a sequence of amino acids, \ie a protein.
The third step folds this amino acid sequence, imparting further functionality to a now fully realised protein.
An additional step of the central dogma of molecular biology is /DNA replication/, where the DNA replicates itself during cell division.
This perpetuation step is not directly considered here when considering gene expression.

Each of these levels of expression can be regulated by environmental factors in the cell.
The concentration of a specific [[gls:tf]], for example, determines how saturated a [[gls:tf]] binding site is and in essence how much the regulated gene is affected.
Each component of the system has an associated number of parameters that refer to specific rate constants of biochemical reactions taking place or parameters of the model used (see: sections [[ref:sec:system-theory]] and [[ref:sec:model-formalism]]).

External signalling also plays a central role in regulating internal molecular concentrations and responses, as demonstrated by for example, the regulatory interactions of the bacterial flagellum.
The bacterial flagellum is an appendage protruding from the bacteria, with the function to move the bacteria in response to external environmental factors.
\\
In short, the bacterium senses a concentration gradient through receptors on the cell membrane, if it is moving.
If the gradient indicates that the bacteria is moving towards something nutritious the behaviour of the flagellum will change and the bacteria will propel itself towards the higher concentration of nutrients.
If no gradient is sensed the behaviour changes and the bacterium tumbles randomly until a new signal appears.
The bacteria also responds to damaging chemicals by reversing the response so the direction of motion is away from the higher concentration [[citep:Berg2000]].

The complex function displayed by the bacteria could not be achieved without predictable regulation.
The regulatory machinery and behaviour of the flagellum can be modelled accurately, and displays several different emergent systems properties.
These include \eg robustness, the function of the regulatory machinery to maintain its function for a wide range of parameters of the system, and exact adaptation, meaning that the bacteria can reset the internal state to be able to respond appropriately to new changes even though the external environment is changed \ie the bacteria counteracts being overwhelmed by chemical stimuli [[citep:Alon2007]].

Reactions taking place in the cell works on several different time scales.
For example in \Coli the time a [[gls:tf]] takes to find and bind to a specific target location takes roughly 1-6 minutes [[citep:Elf2007]].
This is done through diffusion through the cell.
For larger cells or for faster reactions the cell has to rely on different mechanisms for regulation [[citep:Alon2007]].
To get an overview of the interactions or regulatory machinery we can display the interactions, of [[gls:tf]] bindings or protein to protein interactions that we can infer or observe as links in a graph. This is then a network representation of the interactions in the cell.
Including metabolites into the network expands the description beyond the interactions of genes to encompass other cell signalling phenomena.
We can also model a cellular regulatory network by quantifying the interactions with a direction of influence, \ie if the interaction is increasing or decreasing the activity or expression of the target.
This would then constitute the cellular regulatory network.

#+CAPTION[Biological network hierarchy]: Different hierarchical levels of displaying the cellular regulatory network. The arrows indicates direction of regulation; if the head of the link is an arrow it means the interaction is activating and if the head of the link is T shaped it means the interaction is suppressing. Figure inspired by [[citet:Crampin2006]].
#+label: fig:net-hierarchy
[[file:img/abstract_network.pdf]]

Figure [[ref:fig:net-hierarchy]] shows a hierarchical separation of different regulatory networks in the cell.
The interconnected nature of these intercellular components does not lend itself to differentiation and thus many of these relationships cannot be well defined in a real cell. Here, however, they are separated by concepts, and in some regards, measuring techniques.
In the figure we have the metabolic layer, depicting the path of different metabolites or transformations of metabolites, modelled often by mass action kinetics [[citep:Jamshidi2010]].
We also have the protein layer that details the protein to protein interaction network as well as protein complexes.
The formation of a protein complex would constitute a case where the proteins might not have any regulatory effect on each other, or they might not be influencing the rate or change of any of the proteins involved. However, they are still considered an interaction here.
It can be that the complex regulates something else and that all involved proteins need to be present for a regulatory interaction to occur, much like an =AND= operator in a Boolean operation.
The third layer is the gene layer where DNA sequence is transcribed to RNA.
The RNA themselves can have regulatory effects alone, they can become translated into proteins or both.

The dashed lines on the bottom layer are interactions shown as direct influences between genes themselves.
In reality, this can not be the case.
Instead this is a representation of the interactions when the gene products and their cumulative effects through different layers are condensed to a description of interactions between genes.
\\
In the following part of this thesis this abstract layer is what is referred to as the \acrfullpl{grn} and /gene interactions/ should be interpreted as the cumulative effects of the influences of gene products on other gene products, if not stated otherwise.

Discussing the [[gls:grn]] in these terms is partially made for practical reasons.
All nodes of the "true" [[gls:grn]] as depicted in the figure might not be observable under specific experimental setups.
For example, the experimental setup for measuring mRNA, protein and metabolites is very different and is not easily combined on a large scale,
and in some cases the dynamics of one layer might not be representative of those in another layer [[citep:Gygi1999]].
The time scales of reactions for different layers or sub-networks may also vary substantially.
Some interactions may not be observed if measuring the system over several days or under just a few seconds [[citep:Elf2007]].
One can not assume that any given collection of cells being observed are synchronised in expressing different properties or processes.
One cell might be in the process of differentiating, displaying an expression pattern related specifically to that state, while other cells might not be in that state.
A measurement on such a setup reflects an average over the cells in the sample and might not reflect any specific interaction pattern present in any of the individual cells.

It is also common that the different layers of the networks are separated into different databases.
For simpler organisms the [[gls:tf]] network is constructed from curated data and contains a large number of interactions.
/RegulonDB/ [[citep:Salgado2013]] has a large set of [[gls:tf]] binding interactions collected in a regulatory network of \coli, while Yeastract [[citep:Teixeira2013]] hosts a similar database corresponding to \Yeast.
These networks aim at mapping direct binding interactions between gene and gene products, specifically [[glspl:tf]] and binding sites.
It has also been shown that mRNA expression data can be used to construct these networks
[[citep:Faith2007]], and that it can be used to validate or extract knowledge.

**** Network medicine
One of the main areas of practical application for network biology is in medicine.
Roughly $2000$ of human genes are disease associated [[citep:Amberger2009]].
With the high amount of interactors and interactions it is implied that the effects of the disease associations are not isolated to those genes [[citep:Barabasi2011]].
The effect of /comorbidity/ is an indication that a specific disease is not isolated in its effects.
Comorbidity is the ability of a disease to enhance other diseases if some specific disease is already present.
By building a network of interactions and influences of cellular components a bigger picture can emerge of disease effects on the regulatory system.
By overlaying implicated disease genes on the network one can draw conclusions of other disease associated genes.
The more complete this picture the better the conclusions of such a study [[citep:Barabasi2011]].
# Network medicine see notes

# Predictive, personalised, preventive, participatory.

# [[citep:Morel2004]]

One of the main goals of drug discovery is to find compounds with specific properties that can target and affect pathways with high accuracy with minimal side effects [[citep:Schreiber2000]].
Generating reliable models that predict the effect of a specific perturbation from a drug compound will aid in creating more specific and effective drug treatments.

Great interest and funds for drug development are geared towards curing cancer.
Cancer treatments are usually highly invasive as cancer affects the regulatory operations of the cell itself, altering the signalling pathways and behaviour [[citep:Weinberg1996]].
The effects of cancer are multi-factorial, many times different for each type of cancer, and related to the regulatory system of the cell.
An accurate model of healthy cells would serve as a basis for finding alterations in the regulatory system on a very detailed level.

Systems biology approaches for elucidating the context specific regulatory networks of the cell will aid in creating a medical approach that is, predictive, personalised and preventive [[citep:Flores2013]].

# Medical implications and motivation [[citep:Wolkenhauer2009]]

** System theory
:PROPERTIES:
:CUSTOM_ID: sec:system-theory
:END:
In this section I will give a general description of a system.
I will also introduce [[glspl:ode]] and dynamical systems as a description of how a system is changing over time,
and finally in this section I will give a brief description of properties associated with systems in a [[gls:grn]] framework.

*** System description
:PROPERTIES:
:CUSTOM_ID: sec:system-description
:END:
The representation of a system is as important as learning about the system itself.
Whether mathematical, chemical, graphical or other, an accurate description can help fuel insight into what is being observed.
This is especially important because assumptions of the representation have the potential to confer inaccurate or misleading information.

A mathematical description of a system is \eg
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:system}
  \Psi(\bphi_j,\bxi) = 0
\end{equation}
#+end_src
\noindent
for a multivariate problem, where $\btheta$ is the model parameters of the model and $\Psi$ is the function that connects the independent variables $\bphi_j$,
to the dependent variables, $\bxi$ [[citep:Aster2005]].
# For a discrete linear system ([[ref:eq:system]]) becomes a set of equations to be solved
For example, the commonly used linear mapping is of the form
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:sys_equ}
  \mPhi\btheta = \bxi
\end{equation}
Here independent variables $\phi_{ij}$ are mapped by the parameters $\btheta$ to the dependant variables $\xi_i$.
For $n=3$ variables and $m$ data points recorded, this becomes
\begin{equation}
  \begin{bmatrix}
    \phi_{11} & \phi_{21} & \phi_{31}\\
    \phi_{12} & \phi_{22} & \phi_{32}\\
    \vdots & \vdots & \vdots \\
    \phi_{1m} & \phi_{2m} & \phi_{3m}\\
  \end{bmatrix}
  \begin{bmatrix}
    \theta_1\\\theta_2\\\theta_3\\
  \end{bmatrix} =
  \begin{bmatrix}
    \xi_1\\ \xi_2\\ \vdots \\ \xi_m
  \end{bmatrix}
\end{equation}
#+end_src
\noindent

In the inverse problem (see section [[ref:sec:inverse-problem]]) one needs to find a set of parameters $\btheta$ that fits the data $(\bxi$,$\mPhi)$.

*** Dynamical systems
A dynamical system describes a set of variables behaviour over time.

A popular method of describing evolving systems is the [[gls:ode]] model, which relates the state of the system to its rate of instantaneous change
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:ode}
  \dot{\bx} = f(\bx,\bp,\bupsilon,t)
\end{equation}
#+end_src
#+LATEX: \noindent
where $\dot{\bx}$ is the rate of change of the states $\bx$ representing some measurable quantity, in the context of [[glspl:grn]] this is typically mRNA expression or protein abundance.
$\bp$ is any input to the system, henceforth called perturbation, and $\bupsilon$ is stochastic effects, or noise affecting the evolution of the system. $f$ may be any function and $t$ the time.
Now
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:ode-output}
  \by = g(\bx(t),\bepsilon)
\end{equation}
#+end_src
#+LATEX: \noindent
describes the output variables $\by$ as a function, $g$, of the states $\bx$ and the noise term $\bepsilon$, the output variables may be the the same as the input variables.

*** System properties

**** Network motifs
Some specific network motifs have been shown to be over represented in biological systems, as demonstrated by investigating the transcriptional network of \coli and \yeast [[citep:Milo2002]], while others are underrepresented, compared to what would be expected of random networks.
Of special note is the [[gls:ffl]] motif, which is highly over represented.
One hypothetical reason for evolution of the under- or over- representation of specific regulatory motifs is that they serve specific functions, such as delayed responses, pulse response, synchronisation clocks, step responses and switches [[citep:Alon2007]].
The [[Glspl:fbl]] motif is often considered in system theoretic approaches, capable of causing highly correlated responses, so called interampatte systems [[citep:Nordling2009]], section [[ref:sec:iaa]].
Motifs may also explain phenotype, when functioning as biological switches [[citep:Wolkenhauer2005]].
Feedback has been shown to help describe the behaviour of bacterial chemotaxis [[citep:Yi2000]]. A few examples of modelling the [[gls:fbl]] are presented in section [[ref:sec:lin-vs-non-lin]].

**** Steady states
:PROPERTIES:
:custom_id: sec:ss
:END:

[[Glspl:ss]] are defined when the rate of change $\dot{\bx} = 0 \equiv f(\bx_0,\bp,T)$ in ([[ref:eq:ode]]).
The nature of the [[gls:ss]] can be elucidated by analysing the system in the vicinity of $f(\bx_0,\bp,T) = 0$, with $T$ being a time when the system is in [[gls:ss]] and $\bx_0$ is the state of the system at [[gls:ss]].
The solution to the system of equations for $\bx_0$ in multivariate analysis, is the [[gls:ss]].
For the system $f(\bx_0) = 0$ we can calculate the jacobian, $J$, the partial derivatives of $f$ over the states $\bx$.
The nature of the [[glspl:ss]] can then be derived from the eigenvalues of $J$ for linear time invariant systems such as the ones studied here.
If the real part of all eigenvalues are negative, then the system trajectories will converge to a stable state if placed in the vicinity of that state.
If any real part is positive an unstable trajectory exists for that state and the system will diverge if placed in the vicinity of that state and will not converge to a stable state where $\dot{\bx} = 0$.
For a linear system ([[ref:eq:linearsys]]) the solution of $f(\bx_0) = 0$ is always unique, meaning only one [[gls:ss]] exists for any linear system.
The eigenvalues of $J$ might reveal that this is an unstable [[gls:ss]] and the system will diverge away from this state [[citep:Khalil1996]].

Non-linear systems might have more complex descriptions of the function $f(\bx_0) = 0$, with multiple [[gls:ss]] solutions.
This means that the system has multiple [[glspl:ss]], where some might correspond to converging states, while others might be unstable [[gls:ss]]. Here, \emph{unstable} means that the system will naturally diverge from its [[gls:ss]] when small perturbations are introduced.
This way of determining the behaviour of the [[gls:ss]] does not generalise to all non-linear systems, but can be used for those that can be linearised around the [[gls:ss]] [[citep:Khalil1996]].

The stability property has been incorporated in algorithms [[citep:Zavlanos2011]] and when collecting data [[citep:Gardner2003]] for inferring [[gls:grn]].
The assumption is that if biological systems would not be stable,
even random variations would eventually accumulate within the system leading to a system collapse [[citep:Kremling2007]].

One simple mechanism in [[glspl:grn]] for maintaining stability is degradation.
As every entity that regulates something else in the system will degrade or be diluted over time as a function of the concentration, an infinite growth can not be maintained.
This is because an equilibrium will be reach depending on the growth rate and degradation rates of the molecules [[citep:Alon2007]].

**** Linear vs. Non-linear models
:PROPERTIES:
:CUSTOM_ID: sec:lin-vs-non-lin
:END:

Correct system representation is crucial, as different models will directly propagate unique properties and features.
The model should capture important features of the underlying system while remaining intelligible, giving insight into how the system is assembled and predictions of behaviour under given conditions.
Another practical consideration when choosing a representation is prediction, the possibility of evaluating or retrieving a solution, either analytically or computationally.
Added complexity will often result in longer compute time or harder solution evaluation.

The following section will detail an example of two types of systems, a non-linear representation developed to model enzyme kinetics and a linear representation as a simplified version of the non-linear.

#+CAPTION[Feedback graph]: An abstract graphical representation of a mutual activating feedback circuit of two genes. The ball at the end of the link is a placeholder for an unspecified interaction, if an arrowhead is put there it means an activating interaction and if a T bar is put at the end it means a repression.
#+label: fig:two-gene-feedback
[[file:img/feedback_graph.pdf]]
# Check Alon2007 page 99. also page 115. 119.
# Also check [[citep:Sontag2005]] figure 20.

\noindent
Figure [[ref:fig:two-gene-feedback]] is the graphical, or network, representation of a two gene mutually regulating [[gls:fbl]].
We can mathematically describe this system as a system of first-order [[glspl:ode]],
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:feedback-general}
  \begin{array}{lcr}
    \dot{x}_1 &= f_{G_1}(a_{11},a_{12},\alpha_1,x_1,x_2,\bK_1) &= g_{x_1}\\
    \dot{x}_2 &= f_{G_2}(a_{21},a_{22},\alpha_2,x_1,x_2,\bK_2) &= g_{x_2}\\
  \end{array}
\end{equation}
#+end_src
\noindent
$f_{G_{*}}$ is a function of choice that are chosen based on modelling assumption or purpose and could be different for different interactions.
The parameters of model are $a_{11},a_{12},a_{21}, a_{22}$, $\alpha_1$ and $\alpha_2$.
Any other parameters in the functions $f$ are represented by $\bK_i$.
The states of the system is $x_1$ and $x_2$ represents some quantity related to the gene $G_1$ and $G_2$ respectively.

To simplify somewhat, lets look an activating [[gls:fbl]] with degradation without autoregulation and make $f(G)$ independent of the model parameters $a_{ij}$ and $\alpha_i$, then
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:feedback}
  \begin{array}{lcr}
    \dot{x}_1 &= a_{12} f_{G_2}(x_2) - \alpha_1 x_1 &= g_{x_1} \\
    \dot{x}_2 &= a_{21} f_{G_1}(x_1) - \alpha_2 x_2 &= g_{x_2} \\
  \end{array}
\end{equation}
#+end_src
\noindent
The degradation is here explicitly modelled as a linear effect on the measured quantity representing the gene itself.
The rate of degradation is considered as decay of $x_i$ and captured in the parameter $\alpha_i$.
If we incorporated autoregulation in the model, meaning that \eg $G_1$ would regulate its own expression, with its gene products, we would need to incorporate the parameter $a_{11}$.

Now we can look at some properties of this system.
First lets look at [[gls:ss]].
To find the [[glspl:ss]] we set the rate $\dot{x}_1$ and $\dot{x}_2=0$ and solve for $x_1$ and $x_2$.
To find the behaviour of this system close to its [[gls:ss]]
(see: section [[ref:sec:ss]]) we find the Jacobian matrix,
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:feedback-jacobian}
  J =
  \begin{pmatrix}
    \frac{\partial g_{x_1}}{\partial x_1} & \frac{\partial g_{x_1}}{\partial x_2}\\
    \frac{\partial g_{x_2}}{\partial x_1} & \frac{\partial g_{x_2}}{\partial x_2}\\
  \end{pmatrix}
  =
  \begin{pmatrix}
    -\alpha_1 & a_{12} f^\prime_{G_1}(x_2)\\
    a_{21} f^\prime_{G_2}(x_1) & -\alpha_2\\
  \end{pmatrix}
\end{equation}
#+end_src
\noindent
and behaviour of the [[gls:ss]] is described by the eigenvalues of the Jacobian.
The eigenvalues are calculated by finding the $\lambda$ of
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:feedback-eigenvalues}
\begin{array}{c}
  |J - \lambda \bI| = 0\\
  \\
  (-\alpha_1 - \lambda)(-\alpha_2 - \lambda) - (a_{12} f^\prime_{G_1}(x_2)) (a_{21} f^\prime_{G_2}(x_1)) = 0\\
\end{array}
\end{equation}
#+end_src
#+LATEX: \noindent
where $|.|$ is the determinant and $\bI$ is the identity matrix.
This will evaluate to a quadratic function with two solutions for $\lambda$, one for each eigenvalue.
The eigenvalues are evaluated at the [[gls:ss]], so that $f^\prime_{G_1}(x_2)$ and $f^\prime_{G_2}(x_1)$ are evaluated at the steady state [[citep:Morris2004]].

Lets consider the case where $f_G$ is the linear function for both $G_1$ and $G_2$.
Then ([[ref:eq:feedback]]) will have four parameters $a_{12},a_{21}$ and $\alpha_1,\alpha_2$ and the [[gls:ss]] would look like
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:feedback-linear-ss}
  \begin{array}{ccc}
    0 &= a_{12} x_2 - \alpha_1 x_1\\
    0 &= a_{21} x_1 - \alpha_2 x_2\\
  \end{array}
\end{equation}
#+end_src
\noindent
and the [[gls:ss]] solution is
#+begin_src latex :exports results :results latex
\[
\begin{array}{ccc}
  x_1 &= 0\\
  x_2 &= 0\\
\end{array}
\]
#+end_src
#+LATEX: \noindent
and ([[ref:eq:feedback-eigenvalues]]) will, depending on the parameters $a_{ij}$ and $\alpha_i$, be positive, negative or complex.
Complex eigenvalues always comes in pairs.
The real part of the eigenvalues $\Re(\lambda)$ determines if the system is stable (-) or unstable (+).
The imaginary part $\Im(\lambda)$ determines the oscillatory behaviour of the system.

There is the special case when the [[gls:ss]] solution has the following form
#+begin_src latex :exports results :results latex
\begin{align}\label{eq:det_is_0}
\frac{\alpha_1\alpha_2}{a_{12}a_{21}} &= 1\\
\alpha_1\alpha_2 &= a_{12}a_{21}
\end{align}
#+end_src
#+LATEX: \noindent
This is the case when $J$ is singular.
This means that infinte number of solutions exist for the [[gls:ss]] under these conditions.
This is when the determinant of the jacobian $\det(J) = 0$ and any point in the null space of the system is a [[gls:ss]] [[citep:Khalil1996]].

Now lets look at the nonlinear case when $f_G$ is the [[gls:mm]] kinetics function.
The [[gls:mm]] function has been used to model [[glspl:grn]] before [[citep:August2009]].
Other alternatives can be chosen as well, \eg Hill kinetics or boolean functions.
The [[gls:mm]] function is
#+begin_src latex :exports results :results latex
\begin{equation}
  f_{G_i}(x_j) = \frac{x_j}{x_j + K_{ji}}
\end{equation}
#+end_src
\noindent
for an activator, and
#+begin_src latex :exports results :results latex
\begin{equation}
  f_{G_i}(x_j) = \frac{K_{ji}}{x_j + K_{ji}}
\end{equation}
#+end_src
\noindent
for a repressor, where $j$ indicate the activator or repressor and $i$ the target. $K_{ij}$ is the activator coefficient which relates to the amount of $x_j$ needed to be present until significant activation or repression is achieved.
For [[gls:mm]] the amount of $x_j$ needed for $50\%$ activation of its maximum.

To simplify lets look at mutual activation.
The [[gls:ss]] equations from ([[ref:eq:feedback-general]]) will now be,
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:feedback-non-linear-ss}
  \begin{array}{ccc}
    0 &= a_{12} \frac{x_2}{x_2 + K_{21}} - \alpha_1 x_1\\
    0 &= a_{21} \frac{x_1}{x_1 + K_{12}} - \alpha_2 x_2\\
  \end{array}
\end{equation}
#+end_src
\noindent
We have a [[gls:ss]] at $[x_1,x_2] = [0,0]$ however in this case this is not a unique solution, and we also have a solution at
#+begin_src latex :exports results :results latex
\[
\begin{array}{cc}
  x_1 &= \frac{S_{x_1} S_{x_2} - K_{12} K_{21}}{S_{x_2} + K_{21}}\\
  x_2 &= \frac{S_{x_1} S_{x_2} - K_{12} K_{21}}{S_{x_1} + K_{12}}\\
\end{array}
\]
#+end_src
\noindent
where $S_{x_1}=a_{12}/\alpha_1$ and $S_{x_2}=a_{21}/\alpha_2$.

Some notes on these observations.
For nonlinear systems like the ones with [[gls:mm]] kinetics there could exist more than one [[gls:ss]].
To be able to find the [[gls:ss]] behaviour a set of parameters for the model needs to be chosen.

This particular nonlinear system can not exhibit infinite growth as long as the degradation factor is considered.
The growth rate will eventually be balanced out by the degradation factor.

Depending on if a specific combination of parameters in the equation ([[ref:eq:feedback-jacobian]]) fulfils ([[ref:eq:det_is_0]]) the system becomes singular and an infinite number of solutions can be found for the [[gls:ss]].

The non-linear system that we explored had 6 parameters while the linear system had 4.
Including auto-regulation will increase the number of parameters for the nonlinear system to 10.
For the linear system there is no differentiation between auto-regulation and degradation, which is easily seen by adding auto-regulation to equation ([[ref:eq:feedback]]).
The effects are additive and not independently modelled and no differentiation can be made except that the degradation has a suppressing (-) effect and auto-regulation can have an activating effect switching the sign of the interaction to be positive.

As mentioned before, some care needs to be taken when deciding what model to use to represent the system.
While some features can not be captured by the linear model, such as bi-stability, the increase in complexity and degrees of freedom for the non-linear system can risk creating models that do not represent the underlying biology and by extension increase the demand for more data.

**** Time separated hierarchical systems
:PROPERTIES:
:CUSTOM_ID: sec:hierarchical-systems
:END:

Investigating hierarchies in systems helps us understand the behaviour of the system and can simplify further analysis.
A dynamical system may work on several different time scales.
The time constant $\tau$ can be derived from the eigenvalues of the jacobian, $J$, in essence estimating the scale of the effect of the system changes.
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:time-constant}
  \tau_i \equiv \frac{1}{|\Re(\lambda_i)|}
\end{equation}
#+end_src
\noindent
where $\Re(\lambda_i)$ is the real part of eigenvalue $\lambda$ for gene $i$.

Practically, the time constant is calculated for a nonlinear system around its [[gls:ss]].
Fast and slow modes can be separated either by eigenvalue spectral clustering or by imposing a threshold, $\tau^S$ on the time constant, so that if $\tau_i > \tau^S$, $i$  belongs to the fast modes and to the slow otherwise [[citep:Kremling2007]].

Hierarchical analysis of system dynamics have been used to reduce dimensionality of the system [[citep:Zagaris2003]].
Time scale separation is implicated as being a cause of an interampatte behaviour of a system [[citep:Nordling2009]].

Time scale separation is sometimes a motivation for model reduction to facilitate a simpler model representation.
When the time constants and associated dynamics can be viewed as the system operating in different time scales faster modes than the ones under observation can be considered as [[gls:ss]] and slower modes can be discarded as they are then independent of any changes in the time window [[citep:Kremling2007]].
# [[citep:He2009]] Discusses experimental design section 5.

**** Interampatte systems
:PROPERTIES:
:CUSTOM_ID: sec:iaa
:END:

Interampatteness is a property of biochemical networks that can be recognised by a highly correlated response to system perturbations [[citep:Nordling2009]].
The degree of interampatteness can for liner systems be calculated as the condition number of the static gain matrix.
#+begin_src latex :exports results :results latex
\begin{equation}
  \glssymbol{k}(\mG) = \frac{\overline{\sigma}(\mG)}{\underline{\sigma}(\mG)}
\end{equation}
#+end_src
\noindent
where $\overline{\glssymbol{sigma}}(\mG)$ is the largest [[gls:sigma]] and $\underline{\glssymbol{sigma}}(\mG)$ is the smallest [[gls:sigma]] of $\mG$.

Several data sets have been observed to be ill-conditioned.
This is also the effect of doing measurements on an interampatte system.
The data obtained from perturbing a 10 gene network of the /Snf1/ pathway in \yeast [[citep:Lorenz2009]] had a condition number, $\kappa = 253$, and a data set from a 9 gene network in \coli [[citep:Gardner2003]] had a condition number, $\kappa = 54$.
The corresponding estimated interampatteness degree was $\kappa = 215$ and $\kappa= 154$ respectively.

# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
# Check these numbers

Considering the inverse problem (section [[ref:sec:inverse-problem]]) it is known that the smallest signals in the system has the largest effect on the solution when trying to recover the system.
The smallest signal is often the one most susceptible to noise corruption and by extension is the weak point of the inference.
The perturbation design should counteract the interampatteness of the system under investigation as some responses could be masked by attenuation effects.

** Systems biology
:PROPERTIES:
:CUSTOM_ID: sec:system-biology
:END:

Systems biology aims to find descriptions of biological systems that takes in to account the complex interactions that are typically found within \eg the cellular regulatory network.
A problem sought to be solved by a systems biology approach is to give a qualitative and quantitative understanding of the biological systems as a whole. Sub-problems concerning finding the behaviour and structure of regulatory networks need to be solved and taken in to account to reach this understanding.

The primary step to achieve this is to infer the structure of the network.
This involves what is commonly known as a "top down" approach, contrasting the "bottom up" approach that traditionally means investigating singular regulatory interactions or the specific properties of a biomolecule.
When most of the specific details of the biochemical reactions are known then a "bottoms up" approach can be appropriate to build up a view of the system and investigate emergent behaviour not observed or easily inferred from the parts of the system [[citep:Kremling2007]].
This section will focus on a part of systems biology, namely the inference of causal network models describing \acrfullpl{grn}.
First a brief overview of different model formalism will be given, second a more focused in depth view of linear dynamical models, and third its application to network inference of [[glspl:grn]].

*** Model formalism
:PROPERTIES:
:CUSTOM_ID: sec:model-formalism
:END:
As described in section [[ref:sec:system-description]] we can describe a system generally as ([[ref:eq:system]]).
Depending on the transfer function and response we can describe several different types of systems regularly used in systems biology.
A whole slew of different approaches have been developed or adapted for network inference of [[glspl:grn]].

Correlation based methods measure correlation between variables and infer a link between genes if the correlation is high enough.
To be able to use correlation based methods to infer a directed regulatory network,
and not just an association network, [[gls:tsd]] needs to be used.
# what about partial correlations?

A similar approach is the information theoretic approach.
The information theoretic approach is based on estimating the mutual information of the variation in the expression patterns of measured genes.
The expression space could either be discretised to simplify calculations or used as is.
This type of model extends to nonlinear relationships as mutual information can describe many types behaviours [[citep:Margolin2006]].

Boolean networks links gene expression through boolean operators such as =AND=, =OR= and =NOT= [[citep:Albert2003]].
Boolean interactions are based on the truth table of the interactors.
This means that the expression of each gene needs to be discretised to determine if the gene is =ON= or =OFF= and can be expressed as,
#+begin_src latex :exports results :results latex
\begin{equation}
  \bx(t+1) = f^B(\bx(t))
\end{equation}
#+end_src
\noindent
where $f^B$ is a boolean function and $\bx(t+1)$ is the state  (=ON= / =OFF=) of the state variables at time $t+1$ as a function of the state, $\bx$ at time $t$.
#

Bayesian models are models based on conditional probabilities.
Due to the nature of conditional probabilities the bayesian model can not handle [[glspl:fbl]].
To be able to model [[glspl:grn]] with feedback one need to extend the bayesian model to the dynamic bayesian models.
The Bayesian network is modelled with conditional probabilities
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:bayesian-model}
  \Prob(X_i=x_i|X_j=x_j) = f(x_i|x_j)
\end{equation}
#+end_src
\noindent
where $x$ represent the specific value of the random variable $X$.
For a network one would evaluate the probability of a structure of relationships.
Each network model would then be a product of conditional probabilities based on the structure of the network.

Another class of models is the [[gls:ode]] models ([[ref:eq:ode]]).
Several different models fall under this umbrella.
An example of a nonlinear [[gls:ode]] is a model using \acrfull{mm} kinetics.
This can be extended to include modelling with the cooperative Hill coefficients.
The coefficients in the Hill function determine the steepness of the activation curve.
This could also be replaced in the extreme case with a boolean condition, where activation turns on only if the concentration of some activation molecule reaches a certain level [[citep:Alon2007]].
# non-linear

# linear models
For the linear [[gls:ode]] the rate of change for each gene in the system is the cumulative effect of all other regulators for that gene.
The linear system model will be discussed in detail in section [[ref:sec:linear_models]].

There are several review articles describing different approaches and model formalism for network inference in systems biology, see \eg citep:DeJong2002a,Gardner2005,Hecker2009,Yaghoobi2012 for an overview of the main ones.

# [[citep:Gardner2005]]
# Citation 8 and 12 should detail that linear models have been shown to be more versatile.

One should note that some care has to be taken to the choice of model for fitting the data.
For a non-linear model the degrees of freedom might not be well defined.
Even for very simple models with few parameters very complex patterns of data can be fitted [[citep:Andrae2010]].
If any set of data can be fitted with the model there is no way of discriminating between competing models, and there is no test that can exclude a model over another,
which should be required for a model to be considered descriptive.

*** Linear dynamical models
:PROPERTIES:
:CUSTOM_ID: sec:linear_models
:END:

The benefit of using linear models is that they are simple and can describe various complex phenomena observed in biological systems
such as \eg feedback and feed forward motifs.
Even if the system is nonlinear, as long as the system operates close to [[gls:ss]] a linear model can be approximated to describe the casual interactions.

A mathematical description of the linear system is as follows,
#+begin_src latex :exports results :results latex
\begin{equation}
  \begin{array}{r c l}
    \dot{x}_i(t) &=& \sum_{j=1}^N a_{ij}x_j(t) + p_i(t) - f_i(t)\\
    y_i(t) &=& x_i(t) + e_i(t).
  \end{array}
  \label{eq:linearsys}
\end{equation}
#+end_src
# see \eg \citet{Yuan2011,Gardner2003,Yeung2002}.
#+LATEX: \noindent
If we are using the linear model in a biological systems context then the state vector \(\bx(t)=[x_1(t),x_2(t),\ldots,x_N(t)]^T\) represents mRNA expression changes relative to the initial state we refer to as $t=0$ of the system
The vector \(\bp(t)=[p_1(t),p_2(t),\ldots,p_N(t)]^T\) represents the applied perturbation, which may be corrupted by the noise $\bbf(t)$.
The perturbations could be \eg gene knockdowns using siRNA or gene over-expressions using a plasmid with an extra copy of the gene.
The response vector \(\by(t)=[y_1(t),y_2(t),\ldots,y_N(t)]^T\) represents the measured expression changes that differ from the true expression changes by the noise $\be(t)$.
$a_{ij}$ represents the influence of an expression change of gene $j$ on gene $i$.
If gene $j$ up regulates gene $i$ then $a_{ij}$ is positive and if gene $j$ down regulates gene $i$ then $a_{ij}$ is negative.
If gene $j$ and $i$ have no interaction then $a_{ij} =0$.

Linear [[glspl:ode]] have been used extensively in the context of systems biology.
It has been shown that nonlinear models can be linearised around a [[gls:ss]] or log-transformed to be able to make use of the properties associated with linear systems and that near [[gls:ss]] the kinetics are well described by a linear model [[citep:Crampin2006]].
However, that means that if we are not operating close to a [[gls:ss]] a linear model might give misleading conclusions.
Until the quality of data is such that a clear discrimination between when a simple linear model can explain the data and when it cannot, extra care should be taken when, or if, choosing a more complex model.

**** Steady state data
For [[gls:ssd]] we can simplify ([[ref:eq:linearsys]]) to
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:Linearmap}
  \mY = -\mA^{-1}\mP +\mA^{-1}\mF + \mE
\end{equation}
#+end_src
#+LATEX: \noindent
in matrix notation, when the set of experiments are considered.
$\mY$ is the observed [[gls:ss]] response matrix with measurement error $\mE$, when applying the perturbations $\mP$. $\mF$ is the difference between the true perturbations $\check{\mP}$ and the observed perturbations $\mP$, and $\mA$ is the network represented as a matrix where each element represent an interaction.
Linear systems with steady state data have been used in several network inference projects [[citep:Tegner2003,Gardner2003,Julius2009]].

**** Least squares estimate and prediction error

To find the ordinary least squares estimate of ([[ref:eq:Linearmap]]) we solve for $\mA$,
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:ls}
  \mA_{ls} = -\mP\mY^{\dagger}
\end{equation}
#+end_src
#+LATEX: \noindent
Here $\dagger$ represents the Moore-Penrose generalised matrix inverse.
If the data does not contain any noise we assume we can find an exact solution for $\mA$.
However in general, if we have collected noisy data a solution to the above can not be guaranteed and we need to find the least squares solution $\mA_{ls}$ [[citep:Aster2005]].

To fit the data one wants to find the parameters of the model that minimises the distance to the regression curve that relates the independent and dependent variables [[citep:Aster2005]].
This can be expressed with the following equation,
#+begin_src latex :exports results :results latex
\begin{equation}
  \hat{\mA} = \arg \min_{\mA} ||\mA \mY + \mP||_{L_2}^2
  \label{eq:ols_L2}
\end{equation}
#+end_src
#+LATEX: \noindent
If the noise in $\mF$ and $\mE$ are \iid and normally distributed, $\normall$ with mean $\mu$ and variance, $\lambda$, then the least squares estimate is also the maximum likelihood estimate [[citep:Hastie2009]].

Equation ([[ref:eq:ols_L2]]) is sensitive to outliers due to the nature of the 2-norm, $\norm{.}_2$ and it might be favourable to introduce the 1-norm instead
#+begin_src latex :exports results :results latex
\begin{equation}
  \hat{\mA} = \arg \min_{\mA} ||\mA \mY + \mP||_{L_1}
  \label{eq:ols_L1}
\end{equation}
#+end_src
#+LATEX: \noindent
this norm corresponds to fitting to the median rather than the mean as in ([[ref:eq:ols_L2]]).
For ([[ref:eq:ols_L2]]) the function is differentiable, but for ([[ref:eq:ols_L1]]) it is not.
This problem can be over come by noting that ([[ref:eq:ols_L1]]) is peace-wise differentiable and convex.
Meaning that one can search for the optimal solution by finding the peace-wise optimal solutions [[citep:Aster2005]].

*** Gene Regulatory Network inference
:PROPERTIES:
:CUSTOM_ID: sec:net_inf
:END:

# Also comment on that biological systems are usually considered stable [[ref:sec:ss]]

[[citet:Gardner2005]] separated two types of network inference types, the first or "physical" approach aims at constructing the transcriptional regulatory network directly, \ie to determine the physical binding of one transcription factor to another. This strategy concerns itself with direct chemical bonding interactions.
In some cases however, it may be that an intermediate step is not observed and no direct binding occurs even though a change based on influence can be observed.
The second approach is the influence strategy.
For this approach the regulatory influences are sought rather than physical bindings.

As one of the primary objectives of network inference is to find the regulatory interactions, network inference is primarily a model selection problem and not a parameter estimation problem.
However, this line is sometimes blurred with the introduction of algorithms, such as \lasso [[citep:Tibshirani1996]], which both estimate parameters and return a selection of candidate models (see: [[ref:sec:linear_penalty]]).

Several studies have employed a linear dynamical systems framework.
[[citet:Gardner2003]] used a linear model, motivated by linearisation of a nonlinear model around a [[gls:ss]].
Furthermore data was recorded with a [[gls:ss]] assumption on the measured mRNA expression data for 9 genes in the SOS pathway in \coli. A linear regression method was then used to estimate model parameters for an exhaustive search of subsets of interactors for each gene in the network.

A necessary condition to be able to infer a casual influence network from [[gls:ssd]] and a linear dynamical system, section [[ref:sec:linear_models]], is that specific perturbations are made to each gene that is going to be included in the network.
This is the case for [[gls:tsd]] as well with the difference being that for [[gls:tsd]] a single perturbation might be sufficient, and it does not necessarily need to be kept constant until the system relaxes to a [[gls:ss]] [[citep:Dhaeseleer1999]].

# Parameter estimation [[citep:Aster2005]]
#
#

**** Penalised linear regression
:PROPERTIES:
:CUSTOM_ID: sec:linear_penalty
:END:

Based on equation ([[ref:eq:ols_L2]]) and ([[ref:eq:ols_L1]]) we can see that the estimate of $\tilde{\mA}_{ols}$ contains contributions from the noise matrices $\mE$ and $\mF$, even when assuming that the independent variable is noise free, $\mF=0$, we still have to deal with a noisy expression matrix $\tilde{\mY}$.
The result of fitting the data with a noisy $\tilde{\mY}$, is that the estimated model $\mA_{ols}$ tends to be overfitted, meaning that the parameters of the model fits the noise.
This has the consequence that the model fitted to the data does not generalise well to other data with different noise realisations.
For network inference it means that a link can be inferred in the network compensating for the effect of noise.
A network like that is hard to interpret as it usually depicts every gene interacting with every other gene [[citep:Hastie2009]].
An approach to dealing with overfitting is to introduce a penalty term to the model fitting,
#+begin_src latex :exports results :results latex
\begin{equation}
  \hat{\mA}_{\textrm{reg}}(\tilde{\zeta}) = \arg \min_{\mA} ||\bA \bY+\bP||_{L_2}^2 + \zeta||\bA||_{L_2}
  \label{eq:ridge-regression}
\end{equation}
#+end_src
#+LATEX: \noindent
with $\zeta$ corresponding to a parameter that regulates the impact of the penalty term on the ordinary least squares estimate.
The penalty term $\zeta||\bA||_{L_2}$ penalises the model parameters squared size. This has a result that large parameters will be penalised more than smaller.
This approach smooths the parameters of the models, however it does not eliminate model parameters well.

\lasso is another penalty method [[citep:Tibshirani1996]].
The lasso problem can be written as,
#+begin_src latex :exports results :results latex
\begin{equation}
  \hat{\mA}_{\textrm{reg}}(\tilde{\zeta}) = \arg \min_{\mA} ||\bA \bY+\bP||_{L_2}^2 + \tilde{\zeta}||\bA||_{L_1} .
  \label{eq:LASSO}
\end{equation}
#+end_src
#+LATEX: \noindent
The \lasso penalises the absolute size of model parameters.
The difference from the ridge-regression is that \lasso produces different models depending on the penalty parameter \(\zeta\) [[citep:Ng2004]].
The \lasso has the property that it combines model selection with parameter estimation.
Due to this property \lasso has become very popular and a lot of work has been done on investigating the performance, such as its weakness on ill-conditioned data [[citep:Fan2001,Zhao2006,Candes2009,Jia2012]].

As ridge-regression does not suffer the same weaknesses as \lasso, an effort to combine both of these penalties called /elastic-net/ has been made.
The Elastic-net [[citep:Zou2005]] method combines the $L_1$ penalty from \lasso and the $L_2$ penalty from ridge regression. The influence of the penalties are then weighted by a parameter $\alpha$ such that,
#+begin_src latex :exports results :results latex
\begin{equation}
  \hat{\mA}_{\textrm{reg}}(\zeta) = \arg \min_{\mA} C + \tilde{\zeta}\left(\alpha ||\bA||_{L_1} + (1-\alpha)||\bA||_{L_2}^2\right),
  \label{eqn:elastic-net}
\end{equation}
#+end_src
where $C=||\bA \bY+\bP||_{L_2}^2$.
The elasic-net has been shown to be beneficial when compared to other algorithms to infer [[glspl:grn]] [[citep:Gustafsson2010]].

citet:Zou2006 extended the \lasso with the adaptive \lasso algorithm, which introduce a weighting term for each model parameter. These weights should be picked carefully and based on properties of the data, and should in theory be able to overcome the shortcomings of \lasso.

In [[citep:Julius2009]] a structural constraint was introduced to the \lasso penalty derived from /a priori/ knowledge where structure could be specified as being there or not there, positive or negative or uncertain.
An additional constraint was introduced by [[citet:Zavlanos2011]] where the stability of the inferred network was ensured.
In both cases a model similar to the one introduced in section [[ref:sec:linear_models]] was used, with a [[gls:ss]] assumption.

# [[citep:Nordling2013phdthesis]]

# [[citep:Tegner2003]] Don't know how to use this.

# [[citep:Goncalves2008]] Not sure why this is here.

**** Model selection

To choose a "good" model when inferring networks is not trivial.
\lasso produces a range of different models depending on the regularisation parameter $\zeta$.

As mentioned in section [[ref:sec:linear_penalty]] overfitting is an issue when the data is noisy.
The predictive performance of a network estimate can be calculated with the weighted [[gls:rss]],
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:wrss}
  \chi^2(df) \sim \text{W}\RSS(\mA_f) = (\by-\mA_f^{-1}\bp)^T W^{-1} (\by-\mA_f^{-1}\bp)
\end{equation}
#+end_src
\noindent
where $\mA_f$ denotes any network arrived at by any function, with co-variance matrix $W$ of the measurement errors.
If the errors in $\bY$ are \iid and normally distributed, $\normall$ with mean $\mu$ and variance, $\lambda$, then the weighted [[gls:rss]] follows a [[gls:chi2]] distribution with $df$ degrees of freedom [[citep:Aster2005,Andrae2010]].
It is also possible to compare models to determine if one model is significantly better than another.
The ratio of two reduced [[gls:chi2]] distributions with degrees of freedom, $df_1$ and $df_2$,
#+begin_src latex :exports results :results latex
\begin{equation}
  R = \frac{\chi^2_1/df_1}{\chi^2_2/df_2} = \frac{\chi^2_1 df_2}{\chi^2_2 df_1}
\end{equation}
#+end_src
#+LATEX: \noindent
will follow an F distribution with parameters $df_1$ and $df_2$.
And a statistical test can be made to determine how much better one model is over the other [[citep:Aster2005]].

To circumvent the over-fitting problem, one might employ a [[gls:cv]] approach.
[[gls:cv]] means leaving out a part of the data, fitting the model to the remaining data and calculate ([[ref:eq:wrss]]) or simply the [[gls:rss]] on the left out data.
This procedure is repeated for different portions of the data and the error is calculated each time.

# Model selection
Due to the statistical properties of the weighted [[gls:rss]] it is suitable for goodness of fit testing.
If the error is significantly larger than expected the model is discarded.

The prediction error approach is used in the Inferelator [[citep:Bonneau2006]], a network inference framework, together with a [[gls:cv]] scheme to select a model with sufficiently good performance.
The common assumption that [[glspl:grn]] are sparse is used and motivates a selection of a prediction error one standard deviation above the minimum prediction error for selecting the network that is more sparse.

Two other approaches for model selection are the [[gls:bic]] and the [[gls:aic]] [[citep:Akaike1973_with_commentary]].
Both approaches is based on the likelihood function, the [[gls:bic]],
which can be written as
#+begin_src latex :exports results :results latex
\begin{equation}
  \text{BIC} = m \ln\left(\frac{\text{RSS}}{m}\right) + k \ln(m)
\end{equation}
#+end_src
#+LATEX: \noindent
where $m$ is the number of data points, and $k$ the number of free parameters to be estimated.

Both [[gls:bic]] and [[gls:aic]] makes a trade off between model predictability and model complexity,
and both methods have been shown to perform worse than [[gls:cv]] [[citep:Thorsson2005]].

**** Inverse problems
:PROPERTIES:
:CUSTOM_ID: sec:inverse-problem
:END:

[[citet:Aster2005]] describes the nature of the inverse problem, which arises when one tries to estimate model parameters based on measured data or observations related to some independent variables.
This includes the network inference problem and relates to the inference problem's sensitivity to noise.

Looking at equation [[ref:eq:ls]] we can decompose the matrix $\mY =\mU \mSigma \mV^T$, which is just a linear combination of the singular values $\glssymbol{sigma}_k$ and the singular vectors, $\bv_k \bu_k^T$, where $k$ is the specific [[gls:sigma]].
Now the inverse of $\mY$, can be written as another linear combination of these entities,
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:inv-y}
  \mY^{\dagger} \equiv \sum_{k=1}^n \frac{1}{\sigma_k}\bv_k \bu_k^T
\end{equation}
#+end_src
#+LATEX: \noindent
which means that the singular value that has the largest effects on the estimate of ([[ref:eq:ls]]) is the smallest singular value of $\mY$.
The smallest singular value represents the direction in the data with the least variation and least information, meaning that the influence of the noise $\mE$ is potentially substantial as the noise corrupts the smallest variation easier.

From equation ([[ref:eq:inv-y]]) we can derive a definition for an upper bound on the global [[gls:snr]], where
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:snr-E}
  \SNR \equiv \frac{\underline{\sigma}(\mY)}{\overline{\sigma}(\mE)}
\end{equation}
#+end_src
\noindent
and the variables are defined as in ([[ref:eq:Linearmap]]) and $\overline{\sigma}$ represent the largest singular values and $\underline{\sigma}$ represents the smallest non zero singular value.
This can be understood as the largest possible effect the noise can have on the smallest singular value of the measurements.
In practise we do not have access to $\mE$ and we then define the [[gls:snr]] based one the estimated variance of the noise,
#+begin_src latex :exports results :results latex
\begin{equation}\label{eq:snr-lambda}
  \SNR \equiv \frac{\underline{\sigma}(\mY)}{\sqrt{\chi^{-2}(\alpha,df)\lambda(\mY)}}\\
\end{equation}
#+end_src
\noindent
$\chi^{-2}(\alpha,df)$ is the inverse of the [[gls:chi2]] distribution at $\alpha$ significance level and $df$ degrees of freedom.
$\lambda(\mY)$ is the variance of the noise or measurement error of $\mY$.

# any citations?

# discrete inverse problem = parameter estimation problem NOT model identification problem. (maybe only indirectly)

** Network inference -- community efforts
The field of network inference has amassed a collection of tools from various scientific disciplines and a scientifically diverse group of individuals constitutes the network inference community.

In this section I will describe some of the efforts,
resources and approaches that has been built around this research field and how they are connected, as well as giving a reference list of different tools that have been developed in the systems biology field.

*** Benchmarks
Benchmarking can be used as a tool for evaluating the performance of algorithms or methods trying to solve specific problems.
Usually, introducing a new algorithm demands that the claims made of its usefulness is accompanied by a benchmark,
a test against other competing methods or algorithms or some test of performance on data that can be compared to previous estimates [[citep:Margolin2006,Lauria2009,Friedman2010]].
However, it might be the case that new information or better data becomes available at a later date or that the application for the method is expanded.
For this reason larger benchmarks are often conducted with a larger scope than provided by the original analysis [[citep:Bansal2007,Penfold2011]].
These benchmarks have the aim of exploring the performance of methods tested under both a realistic and wide range of conditions as well as against methods of different types and requirements.

Two classes of data are often collected in relation to [[gls:grn]] inference, [[gls:ssd]] and [[gls:tsd]]. Different assumptions follow these different data types.
For [[gls:ssd]] one needs to measure and perturb every gene to be included in the inferred network, see ([[ref:eq:linearsys]]).
For [[gls:tsd]] not all genes needs to be perturbed but enough data needs to capture the regulatory effects in short and long term [[citep:Hecker2009]].

One can focus on one of these data types when benchmarking algorithms \eg [[gls:tsd]] citep:Ward2009,Narendra2011 or mix different approaches that use both types of data [[citep:Bansal2007,Penfold2011]]. The advantage of mixing data is that one can evaluate if any data approach is more informative and if any method approach are to be preferred. The advantage of not mixing data types is that one can more easily isolate specific factors that can influence a specific algorithms performance for a specific data type.

Another feature of the data is the underlying model assumptions.
To make the data more realistic a model based more closely on the underlying theory of how the system operates might be used.
Different model assumptions demand different types of data whether it is to simulate [[gls:insilico]] data or to decide what data needs to be collected from an [[gls:invivo]] setup [[citep:Gardner2005]]. For example, if we consider Boolean networks. If the regulatory structure of the network is such that a gene can not be "turned on" one can not collect all different combinations of inputs required to make a truth table for the inference.
The more regulators the more risk that not all combinations can be realised trivially, and the more data needs to be collected.

The [[gls:dream]] challenge is a community effort and competition that aims at combining the previously mentioned features of benchmarking in addition to including a large contributing community [[citep:Marbach2012]].
The challenges go back to 2007 and has evolved over time.
The [[gls:dream]] challenge is split into several different challenges where one or more are focused on network inference, or identifying unknown regulatory interactions with the help of data and a partly complete network.
The challenges present a mix of [[gls:insilico]] and [[gls:invivo]] data and with some exceptions makes the data available for use when the challenge has finished for use in other works [[citep:Folch-Fortuny2015]].
# May be add more examples than one.

Another core part of any benchmark is how to evaluate the performance of an algorithm being tested and evaluating strengths and weaknesses of methods and approaches.
As a primary aim of network inference is to find the regulatory structure of the [[gls:grn]] one usually tests [[gls:tp]], [[gls:fp]], [[gls:tn]] and [[gls:fn]],
where positive represents a link and negative the absence of a link.
True and false represent the classification an inference method has made if a link should be present or not given that it exist in the gold standard network.
These measures are usually summarised in a more easily interpretable form, such as a fraction of the measures that range between 0 and 1, \eg sensitivity $=\frac{TP}{TP+FN}$, precision $=\frac{TP}{TP+FP}$, specificity $=\frac{TN}{TN+FP}$ and negative prediction value $=\frac{TN}{TN+FN}$ [[citep:Bansal2007]].
What one would like is a single number that represents the performance and is easily compared and understood. The  [[gls:auroc]] and the [[gls:aupr]] are used in many benchmarks, see for example,
# Explain these more.
[[citep:Narendra2011,Marbach2010,Marbach2012]].
Some examples of incorporating the sign of the link has been made [[citep:Hache2009]].
This means extending the binary classification into a more complex structure where you take in to account a link, which is inferred but with the wrong sign.

[[citet:Cantone2009]] generated an [[gls:invivo]] data set from an engineered network. The network was tuned so that the interactions would be known and the network was perturbed and the response was measured both for [[gls:ss]] and [[gls:tsd]]. The purpose of this data set was to be able to benchmark methods on a realistic true model with actual measured data.
Even during these conditions it is shown that inferring the true network is difficult [[citep:Penfold2011]].

*** Data and experiments, \insilico vs. \invivo for benchmarking
:PROPERTIES:
:CUSTOM_ID: sec:data_experiments
:END:

A large collection of toolboxes has been developed aimed at systems biology research.
which focuses mainly on creating simulated [[glspl:grn]] see for example:citep:VandenBulcke2006,Hache2009b,Schaffter2011.

This is a response to the fact that regulatory networks in biology are generally lacking in information and are one of the least available networks types [[citep:Barabasi2011]].
This has to be paired with available data suitable for network inference under stable enough conditions so that the change in the states observed in the data is a consequence of regulatory effects and not for example the network being in a specific mode or that a part of the network is missing, which can happen if genes are deleted.
Toy models and [[gls:insilico]] generated data have been shown to be a good proxy for estimating performance of network inference algorithms [[citep:Bansal2007]]. [[Gls:insilico]] models have been used to predict and tune optimal evolutionary growth through the metabolic network [[citep:Ibarra2002]].
It is also beneficial if one can prepare or extend experimental procedures by first running simulations on a computer and many times it is necessary to be able to maximise the usefulness of the [[gls:invivo]] experimental output [[citep:Nordling2013phdthesis]].

Another benefit of being able to use simulated data is that it is easier to explore and examine a wider range of properties of both network and data.
Networks with different structure and different number of motifs can be generated and methods can be tested on how they perform during specific conditions [[citep:Marbach2012]].

If some knowledge exists, even partial knowledge, one can incorporate this information to get more realistic data sets, such as known regulatory networks [[citep:Schaffter2011]].

For [[gls:invivo]] generated data the concern about "realistic" models or experimental conditions, such as realistic noise models, system response patterns or network structure are taken care of.
Therefore it is desired to generate data in living systems even when testing methods.
For these systems a gold standard network might not exist to estimate network inference performance.
There has been several successful attempts of both data generation and inference including [[gls:invivo]] data and proposed true [[gls:grn]] [[citep:Gardner2003,Cantone2009,Lorenz2009]].
However, even these data sets can be shown to have low quality, such as having low [[gls:snr]] and being ill-conditioned, indicating that there is still work to be done for generating \invivo data sets suitable for [[gls:grn]] inference.

# cites Ljung1999 for identification and perturbation response setup. [[citep:Ljung1999]]

*** Tools of systems biology
In a research field that rely heavily on computation it's unavoidable that a huge number of lines of code and data is generated.
In addition to the scientific knowledge generated with these tools, they are themselves a valuable contribution to the body of scientific knowledge.
# [[citep:Schmidt2006]]
# "Information technology in systems biology."
In this section I will try to collect a number of different tools used in systems biology with the aim of helping with [[gls:grn]] inference.
The tools cover mainly three different areas.
(i) Algorithms and methods for inferring networks, which is the main area of tool development.
Without them the goals of systems biology could not be reached.
(ii) Data formats and communications.
To be able to share data and communicate results and information, common data formats should be developed.
(iii) Simulation and benchmarking.
These tools should accompany any inference method so that it can easily be evaluated.

Table [[ref:tab:inference_methods]] gives an overview of inference methods.
The list is not meant to be exhaustive but instead to give a wide overview of the different approaches available.
For each method the short and long names are given, if available.
The goal of the algorithm together with the modelling scheme is also listed.

Table [[ref:tab:insilico_modelling]] lists a number of tools used for \insilico simulation and modelling.
As detailed in section [[ref:sec:data_experiments]], the demand for testing the array of network inference methods is facilitated by tools that can generate simulated data and networks.

Table [[ref:tab:system_communication]] lists tools and formats for sharing and communicating systems biology data and knowledge.

#  [[citep:Bonneau2008]]

#+BEGIN_LATEX
\begin{landscape}
\footnotesize
#+END_LATEX

#+caption[Inference methods]: List of network inference methods. Short name is the name usually used to refer to the method.
#+label: tab:inference_methods
#+attr_latex: :environment longtable :align |p{4cm}|l|p{5cm}|p{3cm}|p{3cm}|
|----------------------------+-------------+----------------------------------------------------------------------------------------------+------------------------------+-----------------------------------------------|
| Reference                  | Short Name  | Description                                                                                  | Model Scheme                 | Goal                                          |
|----------------------------+-------------+----------------------------------------------------------------------------------------------+------------------------------+-----------------------------------------------|
| [[cite:DiBernardo2005]]        | MNI         | Mode-of-action by network identification                                                     |                              | Determine drug targets                        |
| [[cite:Julius2009]]            |             | \lasso based convex programming implementation with prior constraints                        | ODEs                         | GRN                                           |
| [[cite:Greenfield2010]]        | MCZ         | Median Corrected Z-Scores                                                                    | Information-theoretical      | GRN                                           |
| [[cite:Pinna2010]]             |             | Graph-based method                                                                           | Z-score-based                | GRN                                           |
| [[cite:Grimaldi2011]]          | RegnANN     | Reverse engineered gene networks with artificial neural networks                             | neural networks              | GRN                                           |
| [[cite:Zavlanos2011]]          |             | Inferring stable genetic networks from steady-state data                                     | linear dynamical systems     | GRN                                           |
| [[cite:Xiong2012]]             |             | Method with regression and correlation                                                       | Info-theoretic / LDS         | GRN                                           |
| [[cite:Gardner2003]]           | NIR         | Network identification by multiple regression                                                | ODEs                         | GRN & identify drug targets                   |
| [[cite:Friedman2010]]          | Glmnet      | Lasso (L1) and elastic-net regularized generalised linear models                             |                              | Linear regression                             |
|                            | LSCO        | least squares with cutoff                                                                    |                              |                                               |
| [[cite:Faith2007]]             | CLR         | Context likelihood of relatedness                                                            | Information-theoretical      | GRN                                           |
| [[cite:Jornsten2011]]          | EPoC        | Endogenous perturbation analysis of cancer                                                   |                              | GRN                                           |
| [[cite:Shih2012]]              |             | Single source k-shortest paths algorithm                                                     | graph theory                 | GRN                                           |
| [[cite:Menendez2010]]          | GMRF        | Graphical lasso with Gaussian Markov Random Fields                                           | relevance based              | GRN                                           |
| [[cite:Zou2006]]               |             | Adaptive lasso                                                                               |                              |                                               |
| [[cite:Fan2009]]               |             | SCAD penalty                                                                                 |                              |                                               |
| [[cite:Nordling2011]]          |             | Rank Reduction                                                                               | linear ODE                   | GRN                                           |
| [[cite:Wang2012]]              |             | Inference with kalmar filter                                                                 | combined linear and logistic | GRN                                           |
| [[cite:Nordling2013phdthesis]] | RNI         | Confidence based Robust Network Inference                                                    |                              | GRN                                           |
| [[cite:Wu2008]]                | CCD         | Cyclic coordinate descent Lasso solver                                                       |                              |                                               |
| [[cite:Cosgrove2008]]          | SSEM-Lasso  | Sparse simultaneous equation model – Lasso regression                                        |                              | Determine drug targets                        |
| [[cite:Oates2012]]             |             | Bayesian network using Goldbeter Koshland kinetics                                           | Bayesian                     | Protein-signalling network                    |
| [[cite:Lauria2009]]            | NIRest      | NIR with perturbation estimate                                                               | ODEs                         | estimate P, identify GRN                      |
| [[cite:Margolin2006]]          | ARACNE      | Algorithm for the reconstruction of accurate cellular networks                               | Information-theoretical      | GRN                                           |
| [[cite:Kuffner2012]]           | ANOVA       | ANOVA                                                                                        | ANOVA                        | GRN                                           |
| [[cite:Huynh-Thu2010]]         | GENIE3      | Tree-based method                                                                            | Tree-based                   | GRN                                           |
| [[cite:Castelo2009]]           | Qp-graphs   | Q-order partial correlation graphs                                                           | graph theory                 | GRN                                           |
| [[cite:Ambroise2012]]          | TNIFSED     | Supervised transcriptional network inference from functional similarity and expression data  | supervised                   | Assign probability of being target of each TF |
| [[cite:Mordelet2008]]          | SIRENE      | Supervised inference of regulatory networks                                                  | supervised                   | Assign targets to TFs                         |
| [[cite:Sun2007]]               | TRND        | Transcriptional regulatory network discovery                                                 | Bayesian                     | Assign targets to TFs                         |
| [[cite:DeMatos2012]]           | BC3NET      | Bootstrap aggregation ensemble C3NET                                                         | Information-theoretical      | GRN                                           |
| [[cite:Altay2011]]             | C3NET       | Conservative causal core network inference                                                   | Information-theoretical      | GRN                                           |
| [[cite:Friedman2008]]          |             | Graphical lasso                                                                              |                              | Sparse inverse covariance estimation          |
| [[cite:Bonneau2006]]           | Inferelator | the Inferelator                                                                              | ODEs                         | GRN                                           |
| [[cite:Gevaert2007]]           |             | Bayesian network inference with prior data                                                   | Bayesian                     | GRN                                           |
| [[cite:Lahdesmaki2008]]        | RJMCMC      | Reversible jump Markov chain Monte Carlo                                                     | Bayesian                     | GRN                                           |
| [[cite:Nelander2008]]          | CoPIA       | Combinatorial Perturbation-based Interaction Analysis                                        | ODEs                         | GRN                                           |
| [[cite:Yip2010]]               |             | Integration of knockout and perturbation data                                                | ODEs                         | GRN                                           |
| [[cite:Yu2004]]                | BANJO       | Dynamic Bayesian network inference                                                           | Bayesian                     | GRN                                           |
| [[cite:Djebbari2008]]          |             | Seeded Bayesian networks                                                                     | Bayesian                     | GRN                                           |
| [[cite:Aijo2009]]              |             | Dynamic Bayesian network inference with Guassian processes                                   | Bayesian                     | GRN                                           |
| [[cite:Chai2013]]              |             | Dynamic Bayesian network inference with imputed missing values                               | Bayesian                     | GRN                                           |
| [[cite:Wang2010]]              |             | [Boolean] Process-based network decomposition                                                | Boolean                      | GRN or motifs                                 |
| [[cite:Schulz2012]]            | DREM        | Dynamic Regulatory Events Miner                                                              |                              | More TF-target and timing than GRN            |
| [[cite:Hache2007]]             | GNRevealer  | Reconstructing GNRs with neural networks                                                     | neural networks              | GRN                                           |
| [[cite:Kabir2010]]             |             | Linear time-variant method using self-adaptive differential evolution                        |                              | GRN                                           |
| [[cite:Kuffner2010]]           | PNFL        | Petri net with fuzzy logic                                                                   | petri net                    | GRN                                           |
| [[cite:Grzegorczyk2013]]       |             | Non-homogeneous dynamic Bayesian network                                                     | Bayesian                     | GRN                                           |
| [[cite:Wu2011]]                | SSM         | State space model w/hidden variables                                                         | state space model            | GRN                                           |
| [[cite:Penfold2012]]           |             | Hierarchical non-parametric Bayesian                                                         | Bayesian                     | GRN                                           |
| [[cite:Bock2012]]              |             | Hub-centered GRN inference using automatic relevance                                         | Bayesian                     | GRN or hubs                                   |
| [[cite:Layek2011]]             |             | Boolean networks represented by Karnaugh maps                                                | Boolean                      | GRN                                           |
| [[cite:Kimura2012]]            | LPM         | Linear program machine-based S-system GRN inference method                                   | S-system                     | GRN                                           |
| [[cite:Alakwaa2011]]           | BicAT-Plus  | Bi-clustering with Bayesian for GRN inference                                                | Bayesian                     | GRN                                           |
| [[cite:Li2011]]                | DELDBN      | Differential Equation-based Local Dynamic Bayesian Network                                   | Dynamic Bayesian             | GRN                                           |
| [[cite:August2009]]            |             | Linear convex solver program for biochemical non-linear network inference                    | ODE                          | GRN                                           |
| [[cite:Yuan2011]]              |             | Robust network structure reconstruction                                                      | ODE's/LDS                    | GRN                                           |
| [[cite:Zhang2012]]             | NARROMI     | Noise and redundancy reduction technique using recursive optimisation and mutual information | Info-theoretic and ODEs      | GRN                                           |
|----------------------------+-------------+----------------------------------------------------------------------------------------------+------------------------------+-----------------------------------------------|

#+BEGIN_LATEX
\end{landscape}
#+END_LATEX

#+CAPTION[Dataset generation tools]: Simulation and benchmark data generation tools used for network inference.
#+label: tab:insilico_modelling
#+attr_latex: :align |l|l|p{3cm}|
|-----------------------+-----------------+--------------------------------|
| Reference             | tool            | modelling                      |
|-----------------------+-----------------+--------------------------------|
| [[cite:Schaffter2011]]    | GeneNetWeaver   | Non-linear regulatory networks |
| [[cite:Villaverde2015]]   | BioPreDyn-bench | Ready to run benchmarks        |
| [[cite:Hache2009b]]       | GeNGe           | Non-linear regulatory networks |
| [[cite:VandenBulcke2006]] | SynTReN         | Non-linear regulatory networks |
| [[cite:DiCamillo2009]]    | netsim          | Non-linear regulatory networks |
|-----------------------+-----------------+--------------------------------|


#+CAPTION[Systems biology tools]: Tools for used in systems biology to facilitate communication and results.
#+label: tab:system_communication
#+attr_latex: :align |l|l|p{3cm}|
|-------------------+--------------+-------------------------------------------|
| Reference         | tool         | usage                                     |
|-------------------+--------------+-------------------------------------------|
| [[cite:Almeida2003]]  | SBML         | data format                               |
| [[cite:Miller2010]]   | CellML       | data format with related simulation tools |
| [[cite:MATLAB2014]]   | SimBiology   | simulation and programming                |
| [[cite:Schmidt2006b]] | SBToolbox    | simulation and programming                |
| [[cite:Hoops2006]]    | Copasi       | Dynamic model exploration                 |
| [[cite:Bellot2015]]   | NetBenchmark | Collection of benchmarking tools          |
|-------------------+--------------+-------------------------------------------|

* Present investigations

** Model sparsity selection based on minimum prediction error (PAPER I)
:PROPERTIES:
:CUSTOM_ID: sec:paper1
:END:

Optimal model selection is an open problem.
How to properly choose a specific set of parameters for the network inference algorithms
to determine the optimal sparsity has not been solved.

Some classical alternatives proposed are the [[gls:bic]] and [[gls:aic]], which both trade-off prediction and complexity to find an optimal model,
as well as [[gls:cv]] and selection based on minimisation of the [[gls:rss]].

All these methods for model selection are motivated by the fact that data is recorded with noise and that over-fitting the model is always a risk.
The selection methods have been shown to perform well asymptotically with \eg the number of samples [[citep:Stoica2004]]

In this paper we studied the effects on model selection when the data had a varying degree of information and few samples, typically no higher than twice the number of variables.
Information in the data was defined based on the optimal performance of the inference method [[gls:rni]] on the data when compared to the true network.
If the performance matched the true network for the best model produced by the method, the data set would be considered informative.
When the performance was nonoptimal, but better than random the data set was deemed partly informative, and if the performance was no better than random the data was labelled uninformative.
The informativeness was varied based on two factors, (i) the properties of the network and experimental design, (ii) the [[gls:snr]].

The data used was generated [[gls:insilico]] as this had been utilised with success previously and been shown to be an good indication of how a method would perform on other data [[citep:Menendez2010,Bansal2007]].

We determined two additional steps that should be utilised when solving a network inference and model selection problem.
First, we showed that to be able to utilise a leave out cross validation approach, or as we employ it here, a leave /one/ out cross optimisation (LOOCO), one needs to test for dependence of the sample on the rest of the data and only include the sample in the left out group if it is sufficiently described by the data that is going to be used to infer a network.
The reason for this is that a network inferred from data with no information of a left out sample cannot make any predictions about that sample.
Secondly we introduced a step of re-estimating the parameters returned from an inference algorithm.
Here we argued that because of the penalty used in many inference methods,
to combine model selection and data fitting,
the parameters of the model are not the maximum likelihood estimates, which may skew the [[gls:rss]] for the predictions.
The algorithm for re-estimating the parameters are a [[gls:cls]] algorithm.
[[gls:cls]] preserves the structure of the network while refitting the parameters.
We showed that if the data was uninformative we could not make a useful reliable model selection.
If the data was partly informative or informative,
the model selection based on the [[gls:rss]] would find the model that minimised the [[glspl:fp]] conditioned on the [[glspl:tp]] being maximised.
In practice, giving our selection method a boundery where the minimum [[gls:rss]] could only be achieved when all [[glspl:tp]] were present.

*** Future perspective
We showed that conceptually our approach worked.
However, we did not investigate the performance in general and what the behaviour of our approach would be for a wide variety of data properties.
Several technical additions to a new study would greatly benefit this investigation.

We did not test the [[gls:bic]] and [[gls:aic]] selection methods.
Both of these methods are dependent on the likelihood function and should therefore also have their performance influenced by our additional steps.

The [[gls:rss]] was calculated as the mean [[gls:rss]] over all the selected leave out samples.
A new study would greatly benefit from utilising the statistical properties of the [[gls:rss]], such as if the error of the measurements are assumed to be normal, the [[gls:rss]] will follow a [[gls:chi2]] distribution.
With some care when estimating the degrees of freedom for each model [[citep:Andrae2010]] an exclusion step could then be made where all models not passing a goodness of fit test would be excluded as candidate networks.
The result would be a set of candidate networks in which we could in theory pick any of them.
We would expect, though, that we would pick the sparsest candidate with the argument that [[glspl:grn]] are, in general, sparse.

** Including prior information to enhance network inference accuracy (PAPER II)
:PROPERTIES:
:CUSTOM_ID: sec:paper3
:END:

In this paper we investigated if one could improve inference methods with the help of including prior information.

It is often the case that when trying to solve a network inference problem within biology, the data is under-determined.
This means that a unique solution can not be found for regression models.
It is also usually the case when dealing with biological data that the [[gls:snr]] is low, or that very few replicates have been recorded.

In both these situations it may be beneficial to include prior information. In the first case, if we include prior structural knowledge of the regulatory interactions, we can constrain the problem to a subset of interactions so that it no longer becomes under-determined.
In the second case we might have knowledge that we are confident about of which interactions are more likely to exist and that can help guide an inference method when the data is of poor quality.
In this paper we investigated the latter case.

Available on-line there are a number of databases containing functional associations between genes, collected from a wealth of sources with a number of different evidence types [[citep:Szklarczyk2011,Schmitt2014]].

Incorporating a prior in the network inference pipeline can be done in a number of ways.
In this study we focused on incorporating functional associations, which are usually represented by a number of the confidence that is associated with a link.
These associations are by their nature undirected.
It is often unknown if they are representing direct or indirect links, and if they are parallel or serial.
Therefore, we opted for including the confidence of links as weights inversely proportional to the confidence, meaning that links that have a high confidence give a low weight to the associated penalty term, giving the link a higher chance of being selected.
For example, if the confidence is low but the data indicates a strong link, both effects are traded against each other.
By incorporating the associations as weights it gives the possibility of the data to speak as well.

To test the performance of using a prior in the network inference pipeline, a number of different networks and [[gls:insilico]] data sets were generated.
Two different models of system and data were used,
a linear system model and a non-linear system model [[citep:Schaffter2011]].

Prior incorporation performance was tested by changing the prior accuracy.
Accuracy of the prior was controlling how true links were drawn from distributions of low and high confidence associations.

When the data was uninformative an improvement with the prior could be observed if the prior was more correct than not.
For data generated with the linear model the prior needed on average to be more correct than for a non-linear model.
This also scaled with the [[gls:snr]] of the data sets which in general was higher for the linear system vs non-linear.

We also wanted to test the prior incorporation on real data and used a data collected from \yeast with the gold standard network collected from the Yeastract database [[citep:Teixeira2013]].
To estimate the performance, we checked the overall performance for all models generated by the inference method.
We did this to remove the factor of trying to pick the correct sparsity for the network inference method.
An improvement with the prior could be observed over almost all sparsity levels with an emphasis on the sparser range of the spectrum where we would assume that the optimal network should be found.

*** Future perspective

One question that was not answered in this paper was, at what quality of the data is it useful to include a prior?
While the accuracy of the prior was investigated, the range of [[gls:snr]] was not.
This could prove useful when the accuracy of the prior or the nature of the prior \eg being undirected, might obstruct the inference algorithm.

Due to the evidence types of the prior, the associations might be indirect.
A modified algorithm could make use of this information and instead of inserting a confidence as a weight of an interaction, the association could be incorporated in a way so that the association is preserved in the inferred network even though no direct link would exist, reflecting the nature of the association.

** Practical workarounds for the pitfalls of L1 penalised regression methods (PAPER III)
:PROPERTIES:
:CUSTOM_ID: sec:paper2
:END:

It is known that the performance of penalised regression methods, specifically the $L_1$, penalised \eg [[gls:lasso]], algorithm perform poorly under some conditions [[citep:Zhao2006]].
Sometimes referred to as the predictors having a high co-linearity or the data being ill-conditioned.
In systems theoretic terms this can be quantified by calculating the [[gls:k]] of the data set.
An ill-conditioned matrix has a high degree of co-linearity.
# Better check with Torbjorn if this is correct.

The observation here is that even when the data is informative,
defined as in PAPER I, section [[ref:sec:paper1]],
the $L_1$ penalised methods perform as if the data were only partly informative even when we act as if we had expert knowledge when selecting the optimal network produced by the inference method.
The performance of these types of inference method have been investigated and been shown to be a function of the data and network [[citep:Zhao2006,Marbach2012]].
The issue with these results is that they are impractical in reality as we do not know the network structure beforehand and in some cases we would arrive at the wrong conclusions if we used the wrong network structure to calculate them.

We show that a proxy for predicting the performance of an inference method is to investigate the properties of the data,
specifically the [[gls:k]] and the [[gls:snr]].

We use synthetic data to vary the properties of both network and [[gls:insilico]]  expression data.
We constructed the data so that the properties ranged over known values of properties for real biological data sets.
The properties of the expression data is highly dependant on the network properties but they can be tuned depending on the experimental design [[citep:Nordling2009]].
This is demonstrated with 3 different experimental designs.
Two of the approaches could easily be employed in practise and show specifically that these designs made the data properties highly dependent on the network properties.
The third approach would be more complex and costly to implement in practise and is aimed at minimising the [[gls:k]] for the expression matrix.
It demonstrated clearly that de-coupling the data and network properties and tuning the input so that the data properties would approach more desired states greatly enhanced the performance of the inference and network construction.

While few real data set exists with sufficient data to quantify the properties used in this work and simultaneously have a reference regulatory network,
we picked one data set derived from over expression experiments with three proposed regulatory networks derived experimentally.
From the properties of the data we could reasonably well predict the performance of the inference methods, by comparing to the performance on the [[gls:insilico]] data.

*** Future perspective
One aspect that is rarely incorporated in [[gls:grn]] inference algorithms is the errors-in-variables aspect.
Errors-in-variable models consider measurement errors perturbations, as well as in the measurements.
It is easy to imagine that not only does a perturbation experiment contain noise in the measurement, but in the state of the system when the perturbation is applied as well.
The effect of not considering measurement errors in the independent variables when an error exists has, as far as I know, not been studied within systems biology and [[gls:grn]] inference.

Methods that incorporate [[gls:tls]], which considers errors in variables, opposed to [[gls:ls]] methods, are few and rarely used.

A study on the effect of this could give insight on how to approach this issue and optimise performance on inference with these considerations.

** GeneSPIDER, a software package for a simplified network inference pipeline (PAPER IV)
:PROPERTIES:
:CUSTOM_ID: sec:paper4
:END:

\gs is a software package developed in the computer language and environment [[citet:MATLAB2014]].
The goal of \gs is to provide a simple interface for testing algorithms for network inference of [[glspl:grn]], as well as being able to analyse data acquired from experiments to gain insight into how to proceed with an investigation.

\gs provides functionality for benchmarking network inference methods by generating artificial networks and simulating perturbation experiments on those networks and for measuring performance.
\gs also provides functionality to analyse real world data and guide experimental design.
These two concepts are tightly connected.
Previous benchmark packages have often focused on generating complex models aimed at being as realistic as possible while simulating standard perturbation experiments, like single gene knockout or knockdown.
However, it has been shown that network inference algorithms perform poorly on data generated from simple models with noise levels similar to those found in real data.
This problem is related to experimental design and can be investigated by using simpler models.

\gs takes the approach that it is as important to find out why network inference methods fail as it is creating realistic models.
Models aimed at being realistic are usually very complex, meaning that it can be hard to elucidate or isolate variables that have a direct effect on the performance of the inference.
It is also unclear if a more complex model gives qualitatively better simulations, where simpler models do not give any insight.
In the lab the researcher often has very little control over the network and network properties.
However, the experimental design is under the researchers control to a larger extent than the hidden system under investigation.
Therefore, it makes sense to also investigate what experiments give the most informative data.
This has been done to a large extent in the systems theory field, but it has not been extensively incorporated in benchmarking toolboxes related to [[glspl:grn]].

\gs aims to provide a platform to bridge this gap, with the possibility of investigating optimal perturbation design being as accessible as model simulation.
It is built on previous work and as such provides functionality to solve the problems encountered therein.

*** Future perspective
\gs could be extended to incorporate more variations of expression data \eg [[gls:tsd]] experiments.
This kind of data is also available to the network inference community and suffer many of the same shortcomings as [[gls:ssd]] when considering experimental design toolboxes.

Many functions of \gs are under development, such as optimal perturbation design, and therefore programmatically not optimally implemented.
This is partly because the problem formulation is not finalised.
Further work on how to formulate and implement different details of experimental designs and error estimation of both input and output variables and incorporating that in to \gs is on the TODO list for the software package.

* Backmatter                                                        :notitle:
#+LATEX: \backmatterSU

* References                                                        :notitle:
#+LATEX: \renewcommand{\bibname}{References} % changes the header from Bibliography to References
#+LATEX: \begin{scriptsize} % tiny(5) < scriptsize(7) < footnotesize(8) < small (9)

[[bibliographystyle:citestyle]]
[[bibliography:~/research/bibliography.bib,./references.bib]]

#+LATEX: \end{scriptsize}

* Acknowledgements

\parskip=6pt
I am not really the person that spreads his net wide when it comes to social interactions. Even so, I find myself struggling to fit all the people in these few pages that I owe my thanks to for supporting me on this journey.

\noindent
# Family
First I would like to thank my family, we are truly a big family and while I don't meet most of you often enough you are always in my thoughts.
# Mom
I especially would like to thank my mother for always fighting to provide me with the best, and for being a rock where I could always find support.

\noindent
I would also like to take this opportunity to thank my past self for not giving up on me. I will keep in touch, just out of reach.

\noindent
Mari, I could not have done this without you.
Your constant support and positive attitude made this process much simpler than it would have been without you; Jimmy and Britt-Mari, thank you for all the good times during my holidays.

\noindent
Pierre, our history require no words. We never did put Abstras in his final resting place though...

\noindent
David and family, for all the laughs and for always treating me like a member of the family.

\noindent
Patrik, I'm not sure I would be where I am today if it wasn't for you introducing me to programming and all things computer related.

\noindent
Julien and Emma, crazy, smart, deep. No ideas are to wild to be examined in your presence. My time back in good old Göteborg have been much more exciting thanks to you. I look forward to every time we can sit down over a fika and chat for hours.

# Marie with family Sthlm
\noindent
Stockholms Marie, Göte and Evy, who welcomed me with open arms when I needed a place to live when arriving in Stockholm.

# Sonnhammer group
\noindent
I would also like to give /cred/ to the members of the Sonnhammer group, both past and present --
Christoph for always being a friend. I will always be ready for another Zombie raid!
Lizzy make sure to be nice to Christoph when it's his turn to graduate;
Dimitri for your interesting conversations, and for always inviting me when there was an event where we could share our common nerd interests;
Mateusz, I'm glad that you are on your path to becoming a true Emacs guru. At least I got to convert one person!;
Daniel, don't doubt yourself, just rewrite the code!;
Stefanie, for our little talks;
Gabe, for some reason I always felt that you where the only other swede in the group even though your "northern" Swedish words was many times nothing I could understand;
Matt, thanks for removing all those "asses";
\\
To all of you, I hope that we can still find the time to continue with our researchathons, our retro-gaming evenings and all the other goodness that we have enjoyed together.

# Torbjorn
\noindent
I would also like to thank my co-supervisor Torbjörn for introducing me to the world of signal processing, but foremost I would like to thank you for always providing support and insight to life as a person and as a scientist, and for being a person that I can look up to.

# Erik
\noindent
Finally, I would like to thank my supervisor Erik Sonnhammer for giving me this opportunity and for guiding me through my education, for having patience with all my missteps, and for giving me the freedom to explore my own interests.

* Sammanfattning
\parskip=0pt

#+LATEX: \selectlanguage{swedish}

# Systembiologi
Systembiologi studerar biologi ur ett systemperspektiv.
Detta innebär att förutom att undersöka detaljer, så som en specifik gen, en cell eller en individs beteende, i biologiska system undersöker man hur de här komponenterna interagerar med varandra i ett större sammanhang.
När det gäller individer i en population försöker vi skapa oss en bild av hur populationen fungerar utifrån hur individerna interagerar i populationen och inte utifrån individens specifika egenskaper fungerar när denne är isolerad.
Studerar vi gener tittar vi på hur uttrycket av generna, i kombination med uttrycket av andra gener, reglarar hur cellen fungerar och vilka funktioner som cellen kan utföra och använda sig av beroende på hur generana påverkar varandra.

# Klassiskt tillvägagångsätt
Målet är att kunna beskriva hur systemet, i det här fallet cellen, fungerar och att kunna förutsäga vad som kommer hända när olika förändringar sker i och runt cellen.
Det klassiska tillvägagångsättet som använts för att vetenskapligt studera fenomen, att bryta ner ett system i dess beståndsdelar och studera dem ingående för att sedan kunna dra slutsatser om hela systemet har visat sig svårt när man studerar komplexa levande system.
Egenskaper hos systemet som är svåra att förutsäga genom att studera enskilda komponenters egenskaper, har kunnat förklaras när man placerat komponenterna i en specifik kontext.
För gener är denna kontext den biologiska cellen.
\\
Den mänskliga cellen har omkring \mbox{20\,000} proteinkodande gener.
Antalet möjliga interaktioner mellan dem är \mbox{400\,000\,000}.
Inkluderar vi molekyler som kommer utifrån cellen och de olika steg som en gen kan uttryckas i och därför regleras på, ökar snabbt detta tal i storlek.
Att studera alla komponenter i detalj är inte enkelt och att sedan kunna ge en informativ bild av hur systemet fungerar när komponenterna interagerar med varandra är än mer svårforcerat.

# Systembiologiskt tillvägagångsätt
Verktygen och teorierna från systembiologin är framtagna och utvecklade för att kunna generera kunskap under de här förutsättningarna.
Både att kunna rekonstruera och skapa modeller av interaktionerna, så kallade genreglernätverk,
och att kunna dra hållbara slutsatser samt få en mekanistisk förståelse om det underliggande biologiska systemet, faller inom systembiologins forskningsfält.

# Experiment
För att kunna skapa genreglernätverk krävs experiment designade för att kunna generera modeller av genreglernätverk.
Vi måste kunna mäta koncentrationen av flera specifika biologiska molekyler, såsom mRNA och protein, samtidig och med hög precision.
Beroende på vad vi mäter får vi olika sätt att se hur mycket en gen är uttryckt.
För att kunna generera nätverk där vi vet vilken gen som påverkar vilken annan gen krävs att vi utför specifika störningar på cellen som cellen måste svara på.
Hur cellen svarar är en konsekvens av hur cellens reglernätverk är uppbyggt.
Att skapa sådan data är inte trivialt och medför flera problem när målet är att kunna rekonstruera ett nätverk som kan beskriva de underliggande funktionerna och interaktionerna som cellen utför.
Data av den här typen är ofta brusigt vilket gör att de förändringar som cellen gör i svar på våra störningar inte går att observera helt tydligt.
Systemets uppbyggnad och brus är exempel på egenskaper som datan och även systemet vi tittar på har.
Det vi vill veta är till exempel hur mycket brus och mätfel vi ska ta hänsyn till och hur cellens genreglernätverk påverkar våra mätningar.
Den här typen av data är den typ som behövs för att kunna konstruera modeller för genreglernätverk i celler.

# Mitt bidrag
Arbetet som är underlag för denna avhandling fokuserar på de begränsningar som egenskaperna hos data och hos systemet vi observerar, ger när vi försöker ta fram en modell av cellens genreglernätverk.
Dessutom tittar vi på hur egenskaperna hos datan påverkar hur bra vi kan förvänta oss att olika metoder kommer vara på att återskapa interaktioner mellan generna.
\\
Vi tittar också på vad vi måste ta hänsyn till för att olika metoder ska prestera så bra som möjligt och vilka egenskaper som avgör detta.
För att kunna avgöra hur egenskaperna påverkar prestandan hos metoderna som används, behöver vi också veta vilka egenskaper som är viktiga att studera. Detta är det andra viktiga bidraget som behandlas i underlaget till denna avhandling.
Vi visar att specifika egenskaper som vi kan mäta kan leda till slutsatser om hur vi ska analysera den tillgängliga datan.
\\
Det tredje bidraget försöker svara på frågan om det går att inkludera information och evidens som framtagits med annan data för att öka effektiviteten hos metoderna som används.
Här demonstrerar vi att för data av låg kvallite kan inkludering av evidens av annat slag öka effektiviteten hos metoderna.
\\
Slutligen delar vi med oss av de lösningar som tagits fram under tiden vi studerat och löst olika problem genom ett mjukvarupaket i förhoppningen att det kan vara användbart för andra och visar på specifika analysmetoder som borde ingå när man försöker modellera gennätverk.
#+LATEX: \selectlanguage{english}

* Glossaries                                               :notitle:noexport:
#+begin_src latex :exports results :results latex
\printglossary
#+end_src

* COMMENT Ideas and structure

** My publication

[[cite:Tjarnberg2013]]

[[cite:Studham2014]]

[[cite:Tjarnberg2014]]

[[cite:Tjarnberg2015-unpublished]]


** As of yet unplaced citations,

[[cite:Tegner2007]] Perturbations

[[cite:He2006]] time series data


** DONE Check the GeneSPIDER for the network generation reference
To answer the question; what is small world networks.
[[citet:Prettejohn2011]], section 2.6 specifically sais it's not clear what small world mean.

** TODO Comments from [[cite:Zavlanos2011]] about causal models, specifically differential models, should be viewed and incorporated.
- as well as this:
  steady-state measurements (Gardner et al., 2003; Julius et al., 2009; Tegner et al.,2003) or dynamic time-series (Amato et al., 2007; August & Papachristodoulou, 2009; Bansal et al., 2006; Cinquemani et al., 2009; Papachristodoulou & Recht, 2007; Porreca et al., 2008; Sontag et al., 2004; Srividhy et al., 2007)


** Comments from specific sections now removed to here
*** Abstract
Systems biology deals with the problem of studying systems in a biological context, and finding patterns and rules that can not easily be inferred by the studying the individual components of the cell.
In the end the goal is to transfer the knowledge in to general principles to describe the nature of the cell.

The study of biology has for every time we have overcome a new boundary of discovery revealed an overwhelming complexity and diversity,
and it has become more evident the deeper we have probed the rich set of properties being displayed by living systems.
When we discovered the DNA we confirmed the existence a molecule carrying information that could be inherited and a blueprint for controlling the function of the cellular machinery.

The cellular machinery is built up of tens of thousands different components within the cell alone, not counting the external influx and interactions on the outer surface.
Some core concepts have been distilled and crystallised in to general knowledge such as the storage of genetic information in DNA and the direction of expression of different component of where the direction is depicted as going from DNA to RNA to Protein.
This is summarised in the central dogma of molecular biology.
These are simple distilled concepts of highly complex underlying chemical reactions.

Specifically the studies involve elucidating general principles for applying systems biological models and algorithms and retrieve reliable descriptions of the cell functions.
This means investigating the influence of system properties, as well as experimental approaches, on the quality of the inference of the networks to represent intra-cellular interactions.

*** Introduction
It was clear from early on, when the famous physicist Erwin Schrödinger asked the question "What is life"[[cite:Schrodinger1944]] that the field of biological research would gain attention from not only biologist and biochemists and could benefit from input from a diverse array of fields.

While a few components could be studied in detail by traditional biochemical and biophysical approaches, to study all the components that built up the cellular machinery both computational and new theoretical tools would be needed.

the "The Path Forward" section in [[cite:Rao2001]]
# has some nice notes

# Schrodinger what is life [[cite:Schrodinger1944]]

# What is systems biology? [[cite:Vidal2009]]

*** Gene regulation
# figure with a picture of regulation, gene transcribed -> RNA translated -> protein -> regulat transcription or RNA translation | RNA regulate transcription or protein.
# Abstraction levels of regulation
# metabolic protein RNA [[cite:Crampin2006]]
#
# gene expression
#
# regularization

# Discussing pitfalls related to inferring interactions based on the genetic interaction properties, section 4. [[cite:He2009]]

# Different type of regulatory models [[cite:Rao2001]]
# MODELS OF CELLULAR REGULATION
# Metabolism
# Signal Transduction: Bacterial Chemotaxis
# Genetic Swtiches: DNA regulation
# Gene Expression

# bioloigcal functions flagellum [[cite:Sontag2005]]
# specifically section 4 as a starting point.
# in section 3.1 stability is discussed. and in section 3.2 a motivation why other experts are interested in studying these systems.

# biological networks
#

# [[cite:Kremling2007]] A small note about biologically motivated criteria

# Metabolic networks https://en.wikipedia.org/wiki/Metabolic_network

*** Models
# For network inference this problem is extended further bu introducing inter-dependencies in \(\ba\),
# #+begin_src latex :exports results :results latex
# \begin{equation}\label{eq:net_inf_linear_sys}
#   \begin{bmatrix}
#     \phi_{11} & \phi_{21} & \phi_{31}\\
#     \phi_{12} & \phi_{22} & \phi_{32}\\
#     . & . &. \\
#     . & . &. \\
#     . & . &. \\
#     \phi_{1m} & \phi_{2m} & \phi_{3m}\\
#   \end{bmatrix}
#   \begin{bmatrix}
#     a_{11} & a_{21} & a_{31}\\
#     a_{12} & a_{22} & a_{32}\\
#     a_{13} & a_{23} & a_{33}\\
#   \end{bmatrix} =
#   \begin{bmatrix}
#     \xi_{11} & \xi_{21} & \xi_{31}\\
#     \xi_{12} & \xi_{22} & \xi_{32}\\
#     . & . &. \\
#     . & . &. \\
#     . & . &. \\
#     \xi_{1m} & \xi_{2m} & \xi_{3m}\\
#   \end{bmatrix}
# \end{equation}
# #+end_src


*** Linear models
linear models should not be discarded until they are not sufficiently well describing the data, ref model selection, where if the statistical test of RSS(?) is not fitting the data while the data quality is high, high \eg SNR then can one discard a simple model.

# What citation!
[[cite:Crampin2006]]
Model formalism,# Near steady state linear system. Also a nice figure of different levels of network representation, figure 2.

Why use linear models?

Few degrees of freedom/ parameters.
demands "little" data.
Are easy to model.
Linear model and a lot more, this is a review [[cite:DeJong2002a]]

*** Network inference
# see: Zavlanos et al for the quote "The ensemble of both classes form the so-called genetic network identification problem." first section. The following text is interesting as a reference.
**** Network inference challenges
# CHECK TORBJORNS THESIS PAGE 28!!!
# SIC [[cite:Zhao2006]]


*** Model selection
# specifically chi2 and  f distribution and 2 and 1 norm RSS!!! Chapter 2 I think also page 13 example 1.1.
[[cite:Aster2005]]

# RSS, Goodness of fit test
# General system and statistical learning Least squares, RSS page 12

# BIC
# AIC
# [[cite:Umezu2015]] [[cite:Yang2005]] Not yet read, check them out at work

*** Tools
# Tools and formats for systems biology [[cite:Kremling2007]]

*** Observability

# observability 4.2
# Identifiability
#
# Experimental design
# Fisher information matrix 3.1
#

[[cite:Kremling2007]]

# Strong irrepresentable condition

# Robust network inference

# Observability and controllability  [[cite:Kremling2007]]
# May be in relation to experimental design


*** Model selection
An alternative form can be written as
#+begin_src latex :exports results :results latex
\begin{equation}
  \text{BIC} =  \chi^2 + df \ln(m)
\end{equation}
#+end_src
\noindent
where [[gls:chi2]] is the chi square distribution with $df$ degrees of freedom [[cite:Should_be_one_here_from_wikipedia]].

*** Tools
|   | Gepasi | Biochemical model simulation |

** Figures
1. Based on figure 2 in [[cite:Gardner2005]]
2. Abstract network model based on [[cite:Crampin2006]]
   [[cite:Brazhnik2002]] is what it is baesed on.

* Thesis back cover text                                           :noexport:
** Main body
Systems biology studies biology from a systems perspective.
This means that in addition to examining the details of biological mechanisms, i.e. a gene, a cell or an individual's behaviour, systems biology examines how these components interact with each other in a larger perspective.

The goal is to describe how the system works and be able to predict what will happen when various changes take place in or around the cell, for example.

The work underlying this thesis focuses on limitations of data and system properties observed in data we use for developing models of the cellular gene regulatory network.
Additionally, we look at how these properties affect how well different methods perform when trying to recreate the interactions between genes.

The second contribution aims to define data properties crucial to accounting for different methods' performance and how they determine this.
In order to determine how the properties affect the performance of the methods used, we investigate which properties are important.
Here we show that specific measurable properties could lead to an understanding of how to analyse available data.

The third contribution tries to answer the question whether it is possible to include information and evidence which has been inferred elsewhere to increase the efficiency of the methods used.
Here we demonstrate that if the data is of low quality we can include evidence from other sources to enable reconstruction of gene regulatory networks.

We share the solutions developed while resolving these issues through a software package in the hope that it can be useful to others and demonstrate how they should be incorporated when trying to model gene networks.

* Setup code                                                       :noexport:
Code used when exporting to latex
#+name: setup
#+begin_src emacs-lisp :results silent :exports none
(unless (find "thesis-book-SU" org-latex-classes :key 'car
              :test 'equal)
  (add-to-list 'org-latex-classes '("thesis-book-SU" "\\documentclass[11pt]{book}
\\usepackage{thesisStyleSU}
[NO-DEFAULT-PACKAGES]
[PACKAGES]
[EXTRA]"
  ("\\chapter{%s}" . "\\chapter*{%s}")
  ("\\section{%s}" . "\\section*{%s}")
  ("\\subsection{%s}" . "\\subsection*{%s}")
  ("\\subsubsection{%s}" . "\\subsubsection*{%s}"))))
#+end_src

[[https://emacs.stackexchange.com/questions/9492/is-it-possible-to-export-content-of-subtrees-without-their-headings][source]]. This is currently incompatible with the latest org-mode
#+name: test1
#+begin_src emacs-lisp :results silent :exports none
(defun org-remove-headlines (backend)
  "Remove headlines with :notitle: tag."
  (org-map-entries (lambda () (let ((beg (point)))
                                (outline-next-visible-heading 1)
                                (backward-char)
                                (delete-region beg (point))))
                   "noexport" tree)
  (org-map-entries (lambda () (delete-region (point-at-bol) (point-at-eol)))
                   "notitle"))

(add-hook 'org-export-before-processing-hook #'org-remove-headlines)
#+end_src

This is untested.
#+name: test2
#+begin_src emacs-lisp :results silent :exports none
(defun sa-ignore-headline (contents backend info)
  "Ignore headlines with tag `ignoreheading'."
  (when (and (org-export-derived-backend-p backend 'latex 'html 'ascii)
          (string-match "\\`.*nononotitle.*\n"
                (downcase contents)))
    (replace-match "" nil nil contents)))

(add-to-list 'org-export-filter-headline-functions 'sa-ignore-headline)
#+end_src

** File Local variables                                            :noexport:
### Local Variables:
### ispell-local-dictionary: "british"
### End:
